{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/cs_subs.csv')  # unzip this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['subreddit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624289, 3)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624281, 3)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Android                61202\n",
       "learnprogramming       35288\n",
       "cscareerquestions      32935\n",
       "Windows10              27726\n",
       "webdev                 26849\n",
       "dataisbeautiful        24388\n",
       "softwaregore           23741\n",
       "web_design             22159\n",
       "ProgrammerHumor        19206\n",
       "learnpython            17634\n",
       "raspberry_pi           15659\n",
       "iOSBeta                14508\n",
       "linux                  14058\n",
       "javascript             12971\n",
       "linuxquestions         11464\n",
       "hackernews             11134\n",
       "Python                 11119\n",
       "windows                10132\n",
       "androiddev             10130\n",
       "mac                     9841\n",
       "ios                     9754\n",
       "arduino                 9603\n",
       "java                    9401\n",
       "networking              9378\n",
       "linux4noobs             8004\n",
       "androidthemes           7895\n",
       "chrome                  5862\n",
       "iOSProgramming          5647\n",
       "rust                    5489\n",
       "datascience             5374\n",
       "                       ...  \n",
       "redis                    241\n",
       "dartlang                 240\n",
       "programmerreactions      237\n",
       "Julia                    217\n",
       "reviewmycode             216\n",
       "zsh                      210\n",
       "OSXTweaks                198\n",
       "erlang                   186\n",
       "d3js                     179\n",
       "MaterialDesign           179\n",
       "npm                      164\n",
       "c_language               143\n",
       "learnphp                 120\n",
       "Heroku                   118\n",
       "dailyprogrammer          114\n",
       "cakephp                  113\n",
       "learnruby                106\n",
       "mariadb                   95\n",
       "tinycode                  93\n",
       "groovy                    90\n",
       "pythoncoding              88\n",
       "vagrant                   77\n",
       "Cprog                     38\n",
       "androiddesign             36\n",
       "osxterminal               31\n",
       "learnlaravel              28\n",
       "shell                     24\n",
       "haskelltil                24\n",
       "dotfiles                  17\n",
       "AskCompSci                17\n",
       "Name: subreddit, Length: 136, dtype: int64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232338</th>\n",
       "      <td>Pretty clear who sells upvotes imo</td>\n",
       "      <td>1</td>\n",
       "      <td>dataisbeautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310286</th>\n",
       "      <td>Keep in touch with the best web development co...</td>\n",
       "      <td>1</td>\n",
       "      <td>Web_Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27581</th>\n",
       "      <td>Need help with RTC &amp;amp; SD Code</td>\n",
       "      <td>1</td>\n",
       "      <td>arduino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166547</th>\n",
       "      <td>Help creating a static method - basic java</td>\n",
       "      <td>9</td>\n",
       "      <td>javahelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67181</th>\n",
       "      <td>NEW EARN BITCOIN SITE!!!! IF THEY PAY WE´LL BE...</td>\n",
       "      <td>1</td>\n",
       "      <td>crypto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481134</th>\n",
       "      <td>importing two components/classes with one impo...</td>\n",
       "      <td>6</td>\n",
       "      <td>angularjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24426</th>\n",
       "      <td>Spring AMQP 1.7 picks up Spring Boot 1.5 compa...</td>\n",
       "      <td>14</td>\n",
       "      <td>java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514206</th>\n",
       "      <td>Red says its $1,595 Hydrogen smartphone is 'wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155341</th>\n",
       "      <td>Here's a collection of companies that don't do...</td>\n",
       "      <td>377</td>\n",
       "      <td>cscareerquestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489733</th>\n",
       "      <td>Facebook Migrating A Database From InnoDB To M...</td>\n",
       "      <td>16</td>\n",
       "      <td>Database</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  score  \\\n",
       "232338                 Pretty clear who sells upvotes imo      1   \n",
       "310286  Keep in touch with the best web development co...      1   \n",
       "27581                    Need help with RTC &amp; SD Code      1   \n",
       "166547         Help creating a static method - basic java      9   \n",
       "67181   NEW EARN BITCOIN SITE!!!! IF THEY PAY WE´LL BE...      1   \n",
       "481134  importing two components/classes with one impo...      6   \n",
       "24426   Spring AMQP 1.7 picks up Spring Boot 1.5 compa...     14   \n",
       "514206  Red says its $1,595 Hydrogen smartphone is 'wo...      0   \n",
       "155341  Here's a collection of companies that don't do...    377   \n",
       "489733  Facebook Migrating A Database From InnoDB To M...     16   \n",
       "\n",
       "                subreddit  \n",
       "232338    dataisbeautiful  \n",
       "310286    Web_Development  \n",
       "27581             arduino  \n",
       "166547           javahelp  \n",
       "67181              crypto  \n",
       "481134          angularjs  \n",
       "24426                java  \n",
       "514206            Android  \n",
       "155341  cscareerquestions  \n",
       "489733           Database  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are filtering subreddits that have less than 150 posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data['subreddit'].value_counts()\n",
    "counts = counts[counts > 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_values = list(counts.index)\n",
    "data = data[data['subreddit'].isin(top_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Android                61202\n",
       "learnprogramming       35288\n",
       "cscareerquestions      32935\n",
       "Windows10              27726\n",
       "webdev                 26849\n",
       "dataisbeautiful        24388\n",
       "softwaregore           23741\n",
       "web_design             22159\n",
       "ProgrammerHumor        19206\n",
       "learnpython            17634\n",
       "raspberry_pi           15659\n",
       "iOSBeta                14508\n",
       "linux                  14058\n",
       "javascript             12971\n",
       "linuxquestions         11464\n",
       "hackernews             11134\n",
       "Python                 11119\n",
       "windows                10132\n",
       "androiddev             10130\n",
       "mac                     9841\n",
       "ios                     9754\n",
       "arduino                 9603\n",
       "java                    9401\n",
       "networking              9378\n",
       "linux4noobs             8004\n",
       "androidthemes           7895\n",
       "chrome                  5862\n",
       "iOSProgramming          5647\n",
       "rust                    5489\n",
       "datascience             5374\n",
       "aws                     5112\n",
       "javahelp                4829\n",
       "Web_Development         4732\n",
       "reactjs                 4533\n",
       "golang                  4376\n",
       "node                    4061\n",
       "artificial              3839\n",
       "csharp                  3743\n",
       "swift                   3678\n",
       "csshelp                 3399\n",
       "Angular2                3354\n",
       "computerscience         3033\n",
       "haskell                 2987\n",
       "opensource              2909\n",
       "dotnet                  2775\n",
       "softwaredevelopment     2739\n",
       "AskNetsec               2737\n",
       "cpp                     2699\n",
       "coding                  2398\n",
       "laravel                 2384\n",
       "compsci                 2360\n",
       "rails                   2246\n",
       "ruby                    2244\n",
       "css                     2211\n",
       "C_Programming           2171\n",
       "django                  2116\n",
       "Database                2033\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574249, 3)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57,)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of data. Especially for my Macbook. Let's see the average reddit score (upvotes + downvotes) for each subreddit to filter out. I want to do mean and not median since median would just arbitrarily cut the data in half. Hopefully filtering by mean will take relatively larger chunks out of the more popular subreddits than the less popular ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = {}\n",
    "for subreddit in data['subreddit'].unique():\n",
    "    means[subreddit] = data[data['subreddit'] == subreddit]['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Android': 75.0088722590765,\n",
       " 'Angular2': 5.473166368515206,\n",
       " 'AskNetsec': 6.923273657289003,\n",
       " 'C_Programming': 6.593274988484569,\n",
       " 'Database': 2.3162813575996064,\n",
       " 'ProgrammerHumor': 460.36457357075915,\n",
       " 'Python': 19.62010972209731,\n",
       " 'Web_Development': 1.165680473372781,\n",
       " 'Windows10': 14.500180336146578,\n",
       " 'androiddev': 11.89121421520237,\n",
       " 'androidthemes': 30.770867637745408,\n",
       " 'arduino': 12.679683432260752,\n",
       " 'artificial': 7.961448293826518,\n",
       " 'aws': 6.961463223787168,\n",
       " 'chrome': 5.607130672125554,\n",
       " 'coding': 13.21768140116764,\n",
       " 'compsci': 21.0,\n",
       " 'computerscience': 5.429937355753379,\n",
       " 'cpp': 21.44868469803631,\n",
       " 'cscareerquestions': 9.30821314710794,\n",
       " 'csharp': 11.75581084691424,\n",
       " 'css': 5.632745364088648,\n",
       " 'csshelp': 1.5042659605766402,\n",
       " 'dataisbeautiful': 316.7866983762506,\n",
       " 'datascience': 8.189430591737997,\n",
       " 'django': 5.676748582230624,\n",
       " 'dotnet': 10.152072072072071,\n",
       " 'golang': 13.324040219378428,\n",
       " 'hackernews': 4.136428956349919,\n",
       " 'haskell': 24.44258453297623,\n",
       " 'iOSBeta': 11.140887786049076,\n",
       " 'iOSProgramming': 6.810341774393483,\n",
       " 'ios': 7.587656346114414,\n",
       " 'java': 6.7981065844059145,\n",
       " 'javahelp': 2.0778629115758958,\n",
       " 'javascript': 11.282553388327809,\n",
       " 'laravel': 5.533137583892618,\n",
       " 'learnprogramming': 11.639112446157334,\n",
       " 'learnpython': 5.545083361687649,\n",
       " 'linux': 62.09816474605207,\n",
       " 'linux4noobs': 5.7166416791604195,\n",
       " 'linuxquestions': 3.863049546406141,\n",
       " 'mac': 6.823290316024794,\n",
       " 'networking': 9.80251652804436,\n",
       " 'node': 8.397439054420094,\n",
       " 'opensource': 15.785149535922997,\n",
       " 'rails': 4.292520035618878,\n",
       " 'raspberry_pi': 29.78785363050003,\n",
       " 'reactjs': 10.00154423119347,\n",
       " 'ruby': 10.942513368983958,\n",
       " 'rust': 30.038804882492258,\n",
       " 'softwaredevelopment': 1.2789339174881345,\n",
       " 'softwaregore': 112.0459121351249,\n",
       " 'swift': 7.778955954323002,\n",
       " 'web_design': 9.068685409991426,\n",
       " 'webdev': 13.224179671496145,\n",
       " 'windows': 7.781188314251875}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "filtered = []\n",
    "\n",
    "for subreddit in data['subreddit'].unique():\n",
    "    filtered.append(data.loc[(data['subreddit'] == subreddit) & (data['score'] >= means[subreddit])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = pd.concat(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Android                6807\n",
       "linuxquestions         3893\n",
       "cscareerquestions      3772\n",
       "learnpython            3081\n",
       "webdev                 2565\n",
       "hackernews             2563\n",
       "iOSBeta                2424\n",
       "Windows10              2338\n",
       "linux4noobs            2275\n",
       "ProgrammerHumor        2194\n",
       "networking             2174\n",
       "androiddev             2026\n",
       "linux                  2013\n",
       "windows                2005\n",
       "javascript             1880\n",
       "learnprogramming       1813\n",
       "softwaregore           1746\n",
       "ios                    1737\n",
       "java                   1672\n",
       "androidthemes          1664\n",
       "chrome                 1548\n",
       "Python                 1474\n",
       "aws                    1471\n",
       "rust                   1466\n",
       "web_design             1361\n",
       "javahelp               1326\n",
       "arduino                1205\n",
       "iOSProgramming         1190\n",
       "mac                    1150\n",
       "csshelp                1101\n",
       "datascience            1081\n",
       "AskNetsec              1079\n",
       "golang                 1058\n",
       "raspberry_pi           1037\n",
       "reactjs                1030\n",
       "haskell                1018\n",
       "Angular2                930\n",
       "csharp                  915\n",
       "node                    901\n",
       "artificial              865\n",
       "dataisbeautiful         864\n",
       "cpp                     822\n",
       "dotnet                  795\n",
       "swift                   790\n",
       "computerscience         779\n",
       "ruby                    698\n",
       "rails                   691\n",
       "laravel                 612\n",
       "opensource              584\n",
       "django                  552\n",
       "css                     540\n",
       "C_Programming           511\n",
       "coding                  501\n",
       "compsci                 480\n",
       "Database                344\n",
       "Web_Development         263\n",
       "softwaredevelopment     178\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83852, 3)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83744, 3)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = filtered_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>164326</th>\n",
       "      <td>CSS FizzBuzz</td>\n",
       "      <td>15</td>\n",
       "      <td>css</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468759</th>\n",
       "      <td>Few questions regarding WPF.</td>\n",
       "      <td>13</td>\n",
       "      <td>csharp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510410</th>\n",
       "      <td>d-carousel: A different way of doing carousels</td>\n",
       "      <td>25</td>\n",
       "      <td>webdev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312040</th>\n",
       "      <td>How to deploy your server-side Swift project t...</td>\n",
       "      <td>52</td>\n",
       "      <td>swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588683</th>\n",
       "      <td>[Feature] New text for clock icon</td>\n",
       "      <td>70</td>\n",
       "      <td>iOSBeta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466587</th>\n",
       "      <td>std::visit is everything wrong with modern C++</td>\n",
       "      <td>185</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303838</th>\n",
       "      <td>I'm 36 am I too young to learn and change career?</td>\n",
       "      <td>712</td>\n",
       "      <td>learnprogramming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620542</th>\n",
       "      <td>[Discussion] What icons are those?</td>\n",
       "      <td>125</td>\n",
       "      <td>androidthemes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223610</th>\n",
       "      <td>How to manage Apple Membership Programs &amp;amp; ...</td>\n",
       "      <td>21</td>\n",
       "      <td>swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488893</th>\n",
       "      <td>Find the programmer</td>\n",
       "      <td>9985</td>\n",
       "      <td>ProgrammerHumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204828</th>\n",
       "      <td>Neural network training very slowly</td>\n",
       "      <td>4</td>\n",
       "      <td>javahelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568350</th>\n",
       "      <td>Continuations &amp;amp; Filters with Ron Pressler ...</td>\n",
       "      <td>14</td>\n",
       "      <td>java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231592</th>\n",
       "      <td>good reversing books</td>\n",
       "      <td>14</td>\n",
       "      <td>AskNetsec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501175</th>\n",
       "      <td>Video intro to using Badger key-value store</td>\n",
       "      <td>18</td>\n",
       "      <td>golang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125711</th>\n",
       "      <td>What could you do after CS50?</td>\n",
       "      <td>33</td>\n",
       "      <td>learnprogramming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41942</th>\n",
       "      <td>I just cleaned a virus originating from a .js ...</td>\n",
       "      <td>65</td>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277345</th>\n",
       "      <td>Help with moving a robocopy script over to linux</td>\n",
       "      <td>7</td>\n",
       "      <td>linuxquestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54199</th>\n",
       "      <td>IPv6 client connecting to IPv4 server</td>\n",
       "      <td>15</td>\n",
       "      <td>learnprogramming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185300</th>\n",
       "      <td>Comprehensive tutorial on setting up Webpack 2</td>\n",
       "      <td>63</td>\n",
       "      <td>webdev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338732</th>\n",
       "      <td>Memory Conscious Programming in Ruby</td>\n",
       "      <td>34</td>\n",
       "      <td>ruby</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  score  \\\n",
       "164326                                       CSS FizzBuzz     15   \n",
       "468759                       Few questions regarding WPF.     13   \n",
       "510410     d-carousel: A different way of doing carousels     25   \n",
       "312040  How to deploy your server-side Swift project t...     52   \n",
       "588683                  [Feature] New text for clock icon     70   \n",
       "466587     std::visit is everything wrong with modern C++    185   \n",
       "303838  I'm 36 am I too young to learn and change career?    712   \n",
       "620542                 [Discussion] What icons are those?    125   \n",
       "223610  How to manage Apple Membership Programs &amp; ...     21   \n",
       "488893                                Find the programmer   9985   \n",
       "204828                Neural network training very slowly      4   \n",
       "568350  Continuations &amp; Filters with Ron Pressler ...     14   \n",
       "231592                               good reversing books     14   \n",
       "501175        Video intro to using Badger key-value store     18   \n",
       "125711                      What could you do after CS50?     33   \n",
       "41942   I just cleaned a virus originating from a .js ...     65   \n",
       "277345   Help with moving a robocopy script over to linux      7   \n",
       "54199               IPv6 client connecting to IPv4 server     15   \n",
       "185300     Comprehensive tutorial on setting up Webpack 2     63   \n",
       "338732               Memory Conscious Programming in Ruby     34   \n",
       "\n",
       "               subreddit  \n",
       "164326               css  \n",
       "468759            csharp  \n",
       "510410            webdev  \n",
       "312040             swift  \n",
       "588683           iOSBeta  \n",
       "466587               cpp  \n",
       "303838  learnprogramming  \n",
       "620542     androidthemes  \n",
       "223610             swift  \n",
       "488893   ProgrammerHumor  \n",
       "204828          javahelp  \n",
       "568350              java  \n",
       "231592         AskNetsec  \n",
       "501175            golang  \n",
       "125711  learnprogramming  \n",
       "41942         javascript  \n",
       "277345    linuxquestions  \n",
       "54199   learnprogramming  \n",
       "185300            webdev  \n",
       "338732              ruby  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_data['title']\n",
    "y = filtered_data['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data into train (60%), val (20%), and test (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50246,)\n",
      "(16749,)\n",
      "(16749,)\n",
      "(50246,)\n",
      "(16749,)\n",
      "(16749,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=17)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=31)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Baseline\n",
    "Simple baseline using tf-idf based approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data['subreddit'])\n",
    "\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_val_vectors = vectorizer.transform(X_val)\n",
    "X_test_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def top_n_accuracy(y_true, probs, n=5):\n",
    "    top_n_list = []\n",
    "    for prob in probs:\n",
    "        top_n_list.append(np.argsort(-prob)[:n])\n",
    "    predictions = []\n",
    "    for prediction, top_n in zip(y_true, top_n_list):\n",
    "        predictions.append(int(prediction in top_n))\n",
    "    return np.sum(predictions) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = nb.predict(X_val_vectors)\n",
    "nb_probs = nb.predict_proba(X_val_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy:\n",
      " 0.343901128426\n",
      "Top 5 accuracy:\n",
      " 0.687444026509\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.20      0.99      0.34      1363\n",
      "          1       0.94      0.32      0.48       180\n",
      "          2       0.50      0.00      0.01       225\n",
      "          3       0.00      0.00      0.00       106\n",
      "          4       0.00      0.00      0.00        67\n",
      "          5       0.60      0.09      0.16       449\n",
      "          6       0.67      0.05      0.10       301\n",
      "          7       0.00      0.00      0.00        53\n",
      "          8       0.55      0.37      0.44       452\n",
      "          9       0.74      0.28      0.40       397\n",
      "         10       0.97      0.40      0.57       326\n",
      "         11       0.95      0.35      0.52       218\n",
      "         12       0.94      0.20      0.33       171\n",
      "         13       0.86      0.56      0.67       281\n",
      "         14       0.84      0.26      0.40       330\n",
      "         15       0.00      0.00      0.00        88\n",
      "         16       0.00      0.00      0.00       106\n",
      "         17       0.00      0.00      0.00       158\n",
      "         18       1.00      0.03      0.06       176\n",
      "         19       0.33      0.88      0.48       739\n",
      "         20       0.20      0.01      0.01       175\n",
      "         21       0.50      0.01      0.02        97\n",
      "         22       0.93      0.48      0.63       233\n",
      "         23       0.99      0.39      0.56       170\n",
      "         24       0.83      0.12      0.21       206\n",
      "         25       1.00      0.07      0.13       112\n",
      "         26       0.64      0.27      0.38       165\n",
      "         27       0.50      0.01      0.02       199\n",
      "         28       0.47      0.11      0.18       499\n",
      "         29       0.94      0.16      0.28       202\n",
      "         30       0.67      0.71      0.69       487\n",
      "         31       0.43      0.07      0.12       235\n",
      "         32       0.72      0.04      0.07       344\n",
      "         33       0.76      0.42      0.54       339\n",
      "         34       0.73      0.06      0.10       284\n",
      "         35       0.37      0.24      0.29       421\n",
      "         36       1.00      0.12      0.21       126\n",
      "         37       0.31      0.11      0.16       357\n",
      "         38       0.29      0.71      0.42       642\n",
      "         39       0.58      0.15      0.23       394\n",
      "         40       0.42      0.02      0.03       460\n",
      "         41       0.28      0.78      0.42       738\n",
      "         42       0.89      0.16      0.26       251\n",
      "         43       0.88      0.45      0.60       441\n",
      "         44       0.82      0.07      0.13       201\n",
      "         45       0.00      0.00      0.00       119\n",
      "         46       0.50      0.03      0.06       127\n",
      "         47       0.91      0.24      0.38       209\n",
      "         48       0.66      0.23      0.35       209\n",
      "         49       0.90      0.07      0.12       137\n",
      "         50       0.92      0.44      0.59       274\n",
      "         51       0.00      0.00      0.00        39\n",
      "         52       0.79      0.06      0.12       349\n",
      "         53       0.40      0.04      0.07       169\n",
      "         54       0.47      0.02      0.05       283\n",
      "         55       0.19      0.36      0.25       473\n",
      "         56       0.67      0.14      0.24       397\n",
      "\n",
      "avg / total       0.56      0.34      0.30     16749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victorkwak/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Top 1 accuracy:\\n', top_n_accuracy(y_val, nb_probs, 1))\n",
    "print('Top 5 accuracy:\\n', top_n_accuracy(y_val, nb_probs, 5))\n",
    "print(classification_report(y_val, nb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC(penalty='l2', loss='squared_hinge', multi_class='ovr', max_iter=1000)\n",
    "svm.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.501288594674\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.87      0.80      1362\n",
      "          1       0.64      0.69      0.67       180\n",
      "          2       0.18      0.10      0.13       105\n",
      "          3       0.36      0.31      0.33       216\n",
      "          4       0.47      0.50      0.48       125\n",
      "          5       0.19      0.15      0.17        91\n",
      "          6       0.81      0.70      0.75       101\n",
      "          7       0.25      0.20      0.22        69\n",
      "          8       0.50      0.06      0.10        18\n",
      "          9       0.65      0.62      0.64        89\n",
      "         10       0.88      0.78      0.82        18\n",
      "         11       0.45      0.37      0.41        38\n",
      "         12       0.61      0.46      0.52       115\n",
      "         13       0.60      0.23      0.33        13\n",
      "         14       0.88      0.74      0.80        19\n",
      "         15       0.33      0.05      0.09        20\n",
      "         16       0.65      0.60      0.62        52\n",
      "         17       0.23      0.30      0.26       391\n",
      "         18       0.40      0.30      0.34       307\n",
      "         19       0.60      0.57      0.58        88\n",
      "         20       0.35      0.37      0.36        49\n",
      "         21       0.06      0.02      0.03        47\n",
      "         22       0.47      0.54      0.50       486\n",
      "         23       0.58      0.54      0.56       393\n",
      "         24       0.65      0.61      0.63       327\n",
      "         25       0.37      0.32      0.34        82\n",
      "         26       0.70      0.64      0.67       252\n",
      "         27       0.65      0.68      0.67       184\n",
      "         28       0.75      0.78      0.77       309\n",
      "         29       0.24      0.20      0.22        59\n",
      "         30       0.30      0.21      0.25        33\n",
      "         31       0.55      0.72      0.62       305\n",
      "         32       0.36      0.15      0.21        62\n",
      "         33       0.04      0.02      0.03       102\n",
      "         34       0.21      0.14      0.17        64\n",
      "         35       0.14      0.08      0.10        95\n",
      "         36       0.59      0.37      0.46        62\n",
      "         37       0.21      0.19      0.20       151\n",
      "         38       0.44      0.32      0.37        57\n",
      "         39       0.10      0.06      0.08        95\n",
      "         40       0.58      0.46      0.51       181\n",
      "         41       0.00      0.00      0.00         8\n",
      "         42       0.55      0.48      0.51        89\n",
      "         43       0.51      0.69      0.59       747\n",
      "         44       0.21      0.16      0.18       166\n",
      "         45       0.35      0.42      0.38       107\n",
      "         46       0.69      0.82      0.75       227\n",
      "         47       0.50      0.44      0.47         9\n",
      "         48       0.90      0.64      0.75        14\n",
      "         49       0.83      0.81      0.82       167\n",
      "         50       0.51      0.52      0.51       219\n",
      "         51       0.54      0.49      0.51        90\n",
      "         52       0.68      0.68      0.68       118\n",
      "         53       0.00      0.00      0.00        26\n",
      "         54       0.71      0.64      0.68       115\n",
      "         55       0.49      0.49      0.49       161\n",
      "         56       0.91      0.78      0.84        51\n",
      "         57       0.57      0.39      0.46        72\n",
      "         58       0.69      0.82      0.75        11\n",
      "         59       0.59      0.69      0.64        49\n",
      "         60       0.48      0.58      0.52        59\n",
      "         61       0.23      0.26      0.25        42\n",
      "         62       0.44      0.36      0.40       209\n",
      "         63       0.34      0.31      0.33       542\n",
      "         64       0.70      0.65      0.67       224\n",
      "         65       0.17      0.04      0.06        28\n",
      "         66       0.29      0.25      0.27        67\n",
      "         67       0.76      0.93      0.84       500\n",
      "         68       0.43      0.38      0.41       255\n",
      "         69       0.47      0.52      0.49       331\n",
      "         70       0.62      0.14      0.23        36\n",
      "         71       0.57      0.65      0.61       335\n",
      "         72       0.28      0.30      0.29       267\n",
      "         73       0.36      0.38      0.37       374\n",
      "         74       0.44      0.35      0.39        51\n",
      "         75       0.84      0.65      0.73       124\n",
      "         76       0.19      0.13      0.15       102\n",
      "         77       0.24      0.19      0.21       396\n",
      "         78       0.38      0.53      0.44       605\n",
      "         79       0.45      0.45      0.45       397\n",
      "         80       0.23      0.20      0.21       420\n",
      "         81       0.18      0.09      0.12        69\n",
      "         82       0.39      0.45      0.42       734\n",
      "         83       0.90      0.75      0.82        24\n",
      "         84       0.50      0.59      0.54       213\n",
      "         85       0.26      0.13      0.18        38\n",
      "         86       0.73      0.58      0.65        38\n",
      "         87       0.45      0.42      0.44        52\n",
      "         88       0.64      0.69      0.66       412\n",
      "         89       0.44      0.44      0.44        27\n",
      "         90       0.49      0.55      0.52       183\n",
      "         91       0.25      0.05      0.08        20\n",
      "         92       0.25      0.18      0.21       114\n",
      "         93       0.75      0.58      0.65        31\n",
      "         94       0.26      0.17      0.21        87\n",
      "         95       0.69      0.61      0.65        74\n",
      "         96       0.83      0.48      0.61        21\n",
      "         97       0.52      0.45      0.48       149\n",
      "         98       0.71      0.69      0.70       227\n",
      "         99       0.65      0.72      0.68       226\n",
      "        100       0.73      0.57      0.64        14\n",
      "        101       0.00      0.00      0.00        12\n",
      "        102       0.68      0.56      0.62       140\n",
      "        103       0.00      0.00      0.00        16\n",
      "        104       0.76      0.78      0.77       295\n",
      "        105       0.83      0.71      0.76        89\n",
      "        106       0.12      0.10      0.11        30\n",
      "        107       0.29      0.33      0.31       313\n",
      "        108       0.51      0.45      0.48       136\n",
      "        109       0.90      1.00      0.95        19\n",
      "        110       0.80      0.52      0.63        23\n",
      "        111       0.28      0.28      0.28       269\n",
      "        112       0.24      0.18      0.21       551\n",
      "        113       0.42      0.41      0.41       444\n",
      "        114       0.67      0.14      0.24        28\n",
      "        115       0.36      0.30      0.33        33\n",
      "        116       0.78      0.44      0.56        16\n",
      "\n",
      "avg / total       0.49      0.50      0.49     19789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_predictions = svm.predict(X_val_vectors)\n",
    "\n",
    "print(accuracy_score(y_val, svm_predictions))\n",
    "print(classification_report(y_val, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "\n",
    "tagged_documents = []\n",
    "tokens = None\n",
    "for text, label in zip(X_train, y_train):\n",
    "    text = text.lower()\n",
    "    tokens = utils.simple_preprocess(text)\n",
    "    tagged_documents.append(TaggedDocument(tokens, [label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['lessons', 'learned', 'from', 'my', 'latest', 'game', 'iteration', 'from', 'stars', 'to', 'over'], tags=[71]),\n",
       " TaggedDocument(words=['little', 'asp', 'net', 'core', 'book'], tags=[112]),\n",
       " TaggedDocument(words=['responsive', 'background', 'images', 'with', 'javascript'], tags=[111]),\n",
       " TaggedDocument(words=['can', 'ssh', 'to', 'virtual', 'machine', 'when', 'ipv', 'is', 'set', 'to', 'automatic', 'dhcp', 'but', 'can', 'ssh', 'when', 'use', 'manual', 'and', 'input', 'my', 'own', 'addresses'], tags=[82]),\n",
       " TaggedDocument(words=['conversational', 'dataset'], tags=[51])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(size=64, window=7, min_count=1, workers=4, iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10405811"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build_vocab(tagged_documents)\n",
    "model.train(tagged_documents, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors = X_train.map(lambda title: model.infer_vector(utils.simple_preprocess(title))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors = np.array(list(X_train_vectors), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59364, 64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC(penalty='l2', loss='squared_hinge', multi_class='ovr', max_iter=1000)\n",
    "svm.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_vectors = X_val.map(lambda title: model.infer_vector(utils.simple_preprocess(title))).values\n",
    "X_val_vectors = np.array(list(X_val_vectors), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predictions = svm.predict(X_val_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29789276871\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.69      0.44      1362\n",
      "          1       0.53      0.73      0.61       180\n",
      "          2       0.00      0.00      0.00       105\n",
      "          3       0.18      0.07      0.11       216\n",
      "          4       0.35      0.06      0.10       125\n",
      "          5       0.00      0.00      0.00        91\n",
      "          6       0.61      0.50      0.55       101\n",
      "          7       0.00      0.00      0.00        69\n",
      "          8       0.00      0.00      0.00        18\n",
      "          9       0.39      0.27      0.32        89\n",
      "         10       0.50      0.06      0.10        18\n",
      "         11       0.00      0.00      0.00        38\n",
      "         12       0.30      0.10      0.14       115\n",
      "         13       0.00      0.00      0.00        13\n",
      "         14       1.00      0.05      0.10        19\n",
      "         15       0.00      0.00      0.00        20\n",
      "         16       0.00      0.00      0.00        52\n",
      "         17       0.08      0.06      0.07       391\n",
      "         18       0.29      0.31      0.30       307\n",
      "         19       0.60      0.03      0.06        88\n",
      "         20       0.00      0.00      0.00        49\n",
      "         21       0.00      0.00      0.00        47\n",
      "         22       0.24      0.28      0.26       486\n",
      "         23       0.24      0.36      0.29       393\n",
      "         24       0.28      0.50      0.36       327\n",
      "         25       0.33      0.01      0.02        82\n",
      "         26       0.38      0.57      0.46       252\n",
      "         27       0.36      0.46      0.40       184\n",
      "         28       0.37      0.61      0.46       309\n",
      "         29       0.00      0.00      0.00        59\n",
      "         30       0.00      0.00      0.00        33\n",
      "         31       0.31      0.42      0.36       305\n",
      "         32       0.00      0.00      0.00        62\n",
      "         33       0.00      0.00      0.00       102\n",
      "         34       0.00      0.00      0.00        64\n",
      "         35       0.00      0.00      0.00        95\n",
      "         36       0.00      0.00      0.00        62\n",
      "         37       0.00      0.00      0.00       151\n",
      "         38       0.00      0.00      0.00        57\n",
      "         39       0.00      0.00      0.00        95\n",
      "         40       0.29      0.15      0.20       181\n",
      "         41       0.00      0.00      0.00         8\n",
      "         42       0.25      0.01      0.02        89\n",
      "         43       0.21      0.36      0.27       747\n",
      "         44       0.00      0.00      0.00       166\n",
      "         45       0.46      0.17      0.25       107\n",
      "         46       0.37      0.63      0.46       227\n",
      "         47       0.00      0.00      0.00         9\n",
      "         48       0.00      0.00      0.00        14\n",
      "         49       0.41      0.68      0.51       167\n",
      "         50       0.34      0.08      0.13       219\n",
      "         51       0.31      0.26      0.28        90\n",
      "         52       0.58      0.58      0.58       118\n",
      "         53       0.00      0.00      0.00        26\n",
      "         54       0.43      0.36      0.39       115\n",
      "         55       0.38      0.17      0.23       161\n",
      "         56       0.61      0.39      0.48        51\n",
      "         57       0.00      0.00      0.00        72\n",
      "         58       0.00      0.00      0.00        11\n",
      "         59       0.50      0.41      0.45        49\n",
      "         60       0.38      0.39      0.38        59\n",
      "         61       0.00      0.00      0.00        42\n",
      "         62       0.37      0.64      0.47       209\n",
      "         63       0.16      0.18      0.17       542\n",
      "         64       0.44      0.54      0.49       224\n",
      "         65       0.00      0.00      0.00        28\n",
      "         66       0.00      0.00      0.00        67\n",
      "         67       0.38      0.69      0.49       500\n",
      "         68       0.21      0.09      0.12       255\n",
      "         69       0.30      0.26      0.28       331\n",
      "         70       0.00      0.00      0.00        36\n",
      "         71       0.32      0.53      0.40       335\n",
      "         72       0.16      0.02      0.04       267\n",
      "         73       0.22      0.26      0.24       374\n",
      "         74       0.00      0.00      0.00        51\n",
      "         75       0.58      0.59      0.59       124\n",
      "         76       0.00      0.00      0.00       102\n",
      "         77       0.12      0.01      0.01       396\n",
      "         78       0.18      0.25      0.21       605\n",
      "         79       0.21      0.24      0.23       397\n",
      "         80       0.09      0.01      0.02       420\n",
      "         81       0.00      0.00      0.00        69\n",
      "         82       0.19      0.35      0.25       734\n",
      "         83       0.67      0.25      0.36        24\n",
      "         84       0.29      0.43      0.35       213\n",
      "         85       0.00      0.00      0.00        38\n",
      "         86       0.49      0.45      0.47        38\n",
      "         87       1.00      0.02      0.04        52\n",
      "         88       0.31      0.61      0.41       412\n",
      "         89       0.00      0.00      0.00        27\n",
      "         90       0.39      0.10      0.16       183\n",
      "         91       0.00      0.00      0.00        20\n",
      "         92       0.00      0.00      0.00       114\n",
      "         93       1.00      0.10      0.18        31\n",
      "         94       0.00      0.00      0.00        87\n",
      "         95       0.41      0.55      0.47        74\n",
      "         96       0.00      0.00      0.00        21\n",
      "         97       0.49      0.27      0.35       149\n",
      "         98       0.36      0.22      0.27       227\n",
      "         99       0.40      0.55      0.47       226\n",
      "        100       0.00      0.00      0.00        14\n",
      "        101       0.00      0.00      0.00        12\n",
      "        102       0.42      0.43      0.43       140\n",
      "        103       0.00      0.00      0.00        16\n",
      "        104       0.40      0.68      0.50       295\n",
      "        105       0.52      0.37      0.43        89\n",
      "        106       0.00      0.00      0.00        30\n",
      "        107       0.15      0.04      0.06       313\n",
      "        108       0.38      0.38      0.38       136\n",
      "        109       0.00      0.00      0.00        19\n",
      "        110       0.00      0.00      0.00        23\n",
      "        111       0.18      0.07      0.11       269\n",
      "        112       0.10      0.04      0.05       551\n",
      "        113       0.30      0.15      0.20       444\n",
      "        114       0.00      0.00      0.00        28\n",
      "        115       0.00      0.00      0.00        33\n",
      "        116       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.25      0.30      0.25     19789\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victorkwak/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_val, svm_predictions))\n",
    "print(classification_report(y_val, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH_STOP_WORDS = frozenset([\n",
    "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
    "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
    "    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
    "    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
    "    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
    "    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
    "    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
    "    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\",\n",
    "    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
    "    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
    "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
    "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
    "    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
    "    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
    "    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
    "    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
    "    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
    "    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
    "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
    "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
    "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
    "    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
    "    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
    "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
    "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
    "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
    "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "\"yourselves\"])\n",
    "\n",
    "\n",
    "def format_for_fastext(X, y, filename):\n",
    "    prefix = '__label__'\n",
    "    f = open(''.join(['data/', filename]), 'w')\n",
    "    for title, label in zip(X, y):\n",
    "        title = title.lower()\n",
    "        tokens = utils.simple_preprocess(title)\n",
    "        tokens = [token for token in tokens if token not in ENGLISH_STOP_WORDS]\n",
    "        f.write(''.join([prefix, str(label), ' ', ' '.join(tokens), '\\n']))\n",
    "    f.close()\n",
    "    \n",
    "format_for_fastext(X_train, y_train, 'reddit_fasttext_train.txt')\n",
    "format_for_fastext(X_val, y_val, 'reddit_fasttext_val.txt')\n",
    "format_for_fastext(X_test, y_test, 'reddit_fasttext_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fasttext(y, X, classifier, n=1):\n",
    "    match = []\n",
    "    for true, string in zip(y, X):\n",
    "        predictions = list(classifier.predict(string, n)[0])\n",
    "        for i in range(n):\n",
    "            predictions[i] = int(predictions[i].split('__label__')[1])\n",
    "        match.append(int(true in predictions))\n",
    "    return np.array(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32002627722472082"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastText as fasttext\n",
    "\n",
    "classifier = fasttext.train_supervised(input='data/reddit_fasttext_train.txt',\n",
    "                                 lr=0.1,\n",
    "                                 epoch=30,\n",
    "                                 dim=64,\n",
    "                                 minn=2,\n",
    "                                 maxn=5\n",
    "                                )\n",
    "\n",
    "correct = test_fasttext(y_val, X_val, classifier)\n",
    "correct.sum() / y_val.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.save_model('models/fasttext.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastText import load_model\n",
    "\n",
    "classifier = load_model('models/fasttext.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72732326039719031"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = test_fasttext(y_val, X_val, classifier, 10)\n",
    "correct.sum() / y_val.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
