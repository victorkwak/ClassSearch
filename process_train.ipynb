{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/cs_subs.csv')  # unzip this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['subreddit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624289, 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624281, 3)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Android                61202\n",
       "learnprogramming       35288\n",
       "cscareerquestions      32935\n",
       "Windows10              27726\n",
       "webdev                 26849\n",
       "dataisbeautiful        24388\n",
       "softwaregore           23741\n",
       "web_design             22159\n",
       "ProgrammerHumor        19206\n",
       "learnpython            17634\n",
       "raspberry_pi           15659\n",
       "iOSBeta                14508\n",
       "linux                  14058\n",
       "javascript             12971\n",
       "linuxquestions         11464\n",
       "hackernews             11134\n",
       "Python                 11119\n",
       "windows                10132\n",
       "androiddev             10130\n",
       "mac                     9841\n",
       "ios                     9754\n",
       "arduino                 9603\n",
       "java                    9401\n",
       "networking              9378\n",
       "linux4noobs             8004\n",
       "androidthemes           7895\n",
       "chrome                  5862\n",
       "iOSProgramming          5647\n",
       "rust                    5489\n",
       "datascience             5374\n",
       "                       ...  \n",
       "redis                    241\n",
       "dartlang                 240\n",
       "programmerreactions      237\n",
       "Julia                    217\n",
       "reviewmycode             216\n",
       "zsh                      210\n",
       "OSXTweaks                198\n",
       "erlang                   186\n",
       "d3js                     179\n",
       "MaterialDesign           179\n",
       "npm                      164\n",
       "c_language               143\n",
       "learnphp                 120\n",
       "Heroku                   118\n",
       "dailyprogrammer          114\n",
       "cakephp                  113\n",
       "learnruby                106\n",
       "mariadb                   95\n",
       "tinycode                  93\n",
       "groovy                    90\n",
       "pythoncoding              88\n",
       "vagrant                   77\n",
       "Cprog                     38\n",
       "androiddesign             36\n",
       "osxterminal               31\n",
       "learnlaravel              28\n",
       "shell                     24\n",
       "haskelltil                24\n",
       "AskCompSci                17\n",
       "dotfiles                  17\n",
       "Name: subreddit, Length: 136, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>577087</th>\n",
       "      <td>NumPy: Confused about Indexing with Slices</td>\n",
       "      <td>4</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584783</th>\n",
       "      <td>Designer with intermediate front-end skills wa...</td>\n",
       "      <td>3</td>\n",
       "      <td>webdev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219350</th>\n",
       "      <td>[C++] unable to get virtual functions to work ...</td>\n",
       "      <td>1</td>\n",
       "      <td>learnprogramming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415682</th>\n",
       "      <td>Dell's Precision 5720 AIO Workstation running ...</td>\n",
       "      <td>0</td>\n",
       "      <td>linux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281637</th>\n",
       "      <td>A clever way to use a $10 intel stock cooler t...</td>\n",
       "      <td>0</td>\n",
       "      <td>mac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589017</th>\n",
       "      <td>Has anyone used the OnOff Shim?</td>\n",
       "      <td>1</td>\n",
       "      <td>raspberry_pi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495626</th>\n",
       "      <td>XSS Attack Embedded in an ERC20 Token Contract...</td>\n",
       "      <td>5</td>\n",
       "      <td>hackernews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377481</th>\n",
       "      <td>The rate message won't go away...looks like I'...</td>\n",
       "      <td>1</td>\n",
       "      <td>softwaregore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280705</th>\n",
       "      <td>How to read Gmail</td>\n",
       "      <td>42</td>\n",
       "      <td>learnpython</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374943</th>\n",
       "      <td>Who's Hiring C++ Devs - Q4 2017</td>\n",
       "      <td>59</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  score  \\\n",
       "577087         NumPy: Confused about Indexing with Slices      4   \n",
       "584783  Designer with intermediate front-end skills wa...      3   \n",
       "219350  [C++] unable to get virtual functions to work ...      1   \n",
       "415682  Dell's Precision 5720 AIO Workstation running ...      0   \n",
       "281637  A clever way to use a $10 intel stock cooler t...      0   \n",
       "589017                    Has anyone used the OnOff Shim?      1   \n",
       "495626  XSS Attack Embedded in an ERC20 Token Contract...      5   \n",
       "377481  The rate message won't go away...looks like I'...      1   \n",
       "280705                                  How to read Gmail     42   \n",
       "374943                    Who's Hiring C++ Devs - Q4 2017     59   \n",
       "\n",
       "               subreddit  \n",
       "577087            Python  \n",
       "584783            webdev  \n",
       "219350  learnprogramming  \n",
       "415682             linux  \n",
       "281637               mac  \n",
       "589017      raspberry_pi  \n",
       "495626        hackernews  \n",
       "377481      softwaregore  \n",
       "280705       learnpython  \n",
       "374943               cpp  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are filtering subreddits that have less than 150 posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data['subreddit'].value_counts()\n",
    "counts = counts[counts > 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_values = list(counts.index)\n",
    "data = data[data['subreddit'].isin(top_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Android                61202\n",
       "learnprogramming       35288\n",
       "cscareerquestions      32935\n",
       "Windows10              27726\n",
       "webdev                 26849\n",
       "dataisbeautiful        24388\n",
       "softwaregore           23741\n",
       "web_design             22159\n",
       "ProgrammerHumor        19206\n",
       "learnpython            17634\n",
       "raspberry_pi           15659\n",
       "iOSBeta                14508\n",
       "linux                  14058\n",
       "javascript             12971\n",
       "linuxquestions         11464\n",
       "hackernews             11134\n",
       "Python                 11119\n",
       "windows                10132\n",
       "androiddev             10130\n",
       "mac                     9841\n",
       "ios                     9754\n",
       "arduino                 9603\n",
       "java                    9401\n",
       "networking              9378\n",
       "linux4noobs             8004\n",
       "androidthemes           7895\n",
       "chrome                  5862\n",
       "iOSProgramming          5647\n",
       "rust                    5489\n",
       "datascience             5374\n",
       "                       ...  \n",
       "windowsinsiders          683\n",
       "jquery                   667\n",
       "operabrowser             647\n",
       "browsers                 586\n",
       "watchOSBeta              581\n",
       "LanguageTechnology       528\n",
       "macapps                  526\n",
       "mongodb                  507\n",
       "rubyonrails              455\n",
       "itsaunixsystem           449\n",
       "djangolearning           428\n",
       "nginx                    420\n",
       "haskellquestions         394\n",
       "lua                      363\n",
       "symfony                  357\n",
       "windows8                 334\n",
       "cprogramming             328\n",
       "Meteor                   316\n",
       "DatabaseHelp             312\n",
       "redis                    241\n",
       "dartlang                 240\n",
       "programmerreactions      237\n",
       "Julia                    217\n",
       "reviewmycode             216\n",
       "zsh                      210\n",
       "OSXTweaks                198\n",
       "erlang                   186\n",
       "d3js                     179\n",
       "MaterialDesign           179\n",
       "npm                      164\n",
       "Name: subreddit, Length: 117, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622909, 3)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of data. Especially for my Macbook. Let's see the average reddit score (upvotes + downvotes) for each subreddit to filter out. I want to do mean and not median since median would just arbitrarily cut the data in half. Hopefully filtering by mean will take relatively larger chunks out of the more popular subreddits than the less popular ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = {}\n",
    "for subreddit in data['subreddit'].unique():\n",
    "    means[subreddit] = data[data['subreddit'] == subreddit]['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Android': 75.0088722590765,\n",
       " 'Angular2': 5.473166368515206,\n",
       " 'AskComputerScience': 4.370666666666667,\n",
       " 'AskNetsec': 6.923273657289003,\n",
       " 'AutoHotkey': 1.8294736842105264,\n",
       " 'C_Programming': 6.593274988484569,\n",
       " 'Clojure': 17.862068965517242,\n",
       " 'Database': 2.3162813575996064,\n",
       " 'DatabaseHelp': 1.2147435897435896,\n",
       " 'IOT': 1.9538461538461538,\n",
       " 'Julia': 11.55299539170507,\n",
       " 'LanguageTechnology': 5.160984848484849,\n",
       " 'MLQuestions': 2.3911630929174787,\n",
       " 'MaterialDesign': 10.139664804469273,\n",
       " 'Meteor': 3.731012658227848,\n",
       " 'OSXTweaks': 4.51010101010101,\n",
       " 'PostgreSQL': 6.54421768707483,\n",
       " 'ProgrammerHumor': 460.36457357075915,\n",
       " 'Python': 19.62010972209731,\n",
       " 'SQLServer': 3.208778173190985,\n",
       " 'UI_Design': 4.922300706357215,\n",
       " 'Web_Development': 1.165680473372781,\n",
       " 'Windows10': 14.500180336146578,\n",
       " 'androiddev': 11.89121421520237,\n",
       " 'androidthemes': 30.770867637745408,\n",
       " 'angularjs': 5.399414776883687,\n",
       " 'arduino': 12.679683432260752,\n",
       " 'artificial': 7.961448293826518,\n",
       " 'aws': 6.961463223787168,\n",
       " 'bash': 4.618069815195072,\n",
       " 'browsers': 1.8754266211604096,\n",
       " 'chrome': 5.607130672125554,\n",
       " 'chrome_extensions': 2.472513089005236,\n",
       " 'coding': 13.21768140116764,\n",
       " 'commandline': 18.727650727650726,\n",
       " 'compsci': 21.0,\n",
       " 'computerforensics': 6.737995824634655,\n",
       " 'computerscience': 5.429937355753379,\n",
       " 'computervision': 4.359840954274354,\n",
       " 'coolgithubprojects': 10.124707259953162,\n",
       " 'cpp': 21.44868469803631,\n",
       " 'cprogramming': 1.298780487804878,\n",
       " 'crypto': 11.673133450911228,\n",
       " 'cscareerquestions': 9.30821314710794,\n",
       " 'csharp': 11.75581084691424,\n",
       " 'css': 5.632745364088648,\n",
       " 'csshelp': 1.5042659605766402,\n",
       " 'd3js': 3.335195530726257,\n",
       " 'dartlang': 10.729166666666666,\n",
       " 'dataisbeautiful': 316.7866983762506,\n",
       " 'datascience': 8.189430591737997,\n",
       " 'datasets': 7.213797035347777,\n",
       " 'django': 5.676748582230624,\n",
       " 'djangolearning': 1.8808411214953271,\n",
       " 'docker': 5.943201376936317,\n",
       " 'dotnet': 10.152072072072071,\n",
       " 'elixir': 14.012224938875306,\n",
       " 'embedded': 2.9100091827364554,\n",
       " 'erlang': 7.833333333333333,\n",
       " 'flask': 4.382978723404255,\n",
       " 'git': 7.203438395415473,\n",
       " 'github': 3.315450643776824,\n",
       " 'golang': 13.324040219378428,\n",
       " 'hackernews': 4.136428956349919,\n",
       " 'haskell': 24.44258453297623,\n",
       " 'haskellquestions': 3.0761421319796955,\n",
       " 'html5': 2.8614173228346456,\n",
       " 'iOSBeta': 11.140887786049076,\n",
       " 'iOSProgramming': 6.810341774393483,\n",
       " 'ios': 7.587656346114414,\n",
       " 'itsaunixsystem': 169.52783964365256,\n",
       " 'java': 6.7981065844059145,\n",
       " 'javahelp': 2.0778629115758958,\n",
       " 'javascript': 11.282553388327809,\n",
       " 'jquery': 2.8545727136431784,\n",
       " 'laravel': 5.533137583892618,\n",
       " 'learnjava': 3.8305837563451774,\n",
       " 'learnprogramming': 11.639112446157334,\n",
       " 'learnpython': 5.545083361687649,\n",
       " 'linux': 62.09816474605207,\n",
       " 'linux4noobs': 5.7166416791604195,\n",
       " 'linuxmemes': 114.78265765765765,\n",
       " 'linuxquestions': 3.863049546406141,\n",
       " 'lua': 3.961432506887052,\n",
       " 'mac': 6.823290316024794,\n",
       " 'macapps': 10.901140684410647,\n",
       " 'mongodb': 2.6942800788954635,\n",
       " 'mysql': 2.0155902004454345,\n",
       " 'networking': 9.80251652804436,\n",
       " 'nginx': 2.538095238095238,\n",
       " 'node': 8.397439054420094,\n",
       " 'npm': 1.8414634146341464,\n",
       " 'opensource': 15.785149535922997,\n",
       " 'operabrowser': 2.7156105100463677,\n",
       " 'osx': 5.668396770472895,\n",
       " 'perl': 7.4260948905109485,\n",
       " 'programmerreactions': 56.29535864978903,\n",
       " 'rails': 4.292520035618878,\n",
       " 'raspberry_pi': 29.78785363050003,\n",
       " 'reactjs': 10.00154423119347,\n",
       " 'redis': 2.887966804979253,\n",
       " 'reviewmycode': 1.2407407407407407,\n",
       " 'ruby': 10.942513368983958,\n",
       " 'rubyonrails': 2.523076923076923,\n",
       " 'rust': 30.038804882492258,\n",
       " 'scala': 12.583864118895965,\n",
       " 'softwaredevelopment': 1.2789339174881345,\n",
       " 'softwaregore': 112.0459121351249,\n",
       " 'swift': 7.778955954323002,\n",
       " 'symfony': 3.518207282913165,\n",
       " 'watchOSBeta': 4.235800344234079,\n",
       " 'web_design': 9.068685409991426,\n",
       " 'webdev': 13.224179671496145,\n",
       " 'windows': 7.781188314251875,\n",
       " 'windows8': 1.5598802395209581,\n",
       " 'windowsinsiders': 6.093704245973646,\n",
       " 'zsh': 3.4857142857142858}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "filtered = []\n",
    "\n",
    "for subreddit in data['subreddit'].unique():\n",
    "    filtered.append(data.loc[(data['subreddit'] == subreddit) & (data['score'] >= means[subreddit])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = pd.concat(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Android                6807\n",
       "linuxquestions         3893\n",
       "cscareerquestions      3772\n",
       "learnpython            3081\n",
       "webdev                 2565\n",
       "hackernews             2563\n",
       "iOSBeta                2424\n",
       "Windows10              2338\n",
       "linux4noobs            2275\n",
       "ProgrammerHumor        2194\n",
       "networking             2174\n",
       "androiddev             2026\n",
       "linux                  2013\n",
       "windows                2005\n",
       "javascript             1880\n",
       "learnprogramming       1813\n",
       "softwaregore           1746\n",
       "ios                    1737\n",
       "java                   1672\n",
       "androidthemes          1664\n",
       "chrome                 1548\n",
       "Python                 1474\n",
       "aws                    1471\n",
       "rust                   1466\n",
       "web_design             1361\n",
       "javahelp               1326\n",
       "arduino                1205\n",
       "iOSProgramming         1190\n",
       "mac                    1150\n",
       "csshelp                1101\n",
       "                       ... \n",
       "operabrowser            221\n",
       "mongodb                 197\n",
       "macapps                 189\n",
       "windowsinsiders         189\n",
       "LanguageTechnology      181\n",
       "softwaredevelopment     178\n",
       "djangolearning          173\n",
       "watchOSBeta             149\n",
       "browsers                142\n",
       "itsaunixsystem          138\n",
       "symfony                 124\n",
       "lua                     121\n",
       "nginx                   120\n",
       "windows8                119\n",
       "haskellquestions        117\n",
       "rubyonrails             117\n",
       "programmerreactions     117\n",
       "dartlang                103\n",
       "Meteor                  101\n",
       "redis                    86\n",
       "Julia                    82\n",
       "npm                      74\n",
       "erlang                   72\n",
       "zsh                      69\n",
       "OSXTweaks                67\n",
       "DatabaseHelp             59\n",
       "MaterialDesign           51\n",
       "d3js                     49\n",
       "cprogramming             48\n",
       "reviewmycode             44\n",
       "Name: subreddit, Length: 117, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99057, 3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98941, 3)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = filtered_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>448227</th>\n",
       "      <td>ReactJs component lifecycle methods — A deep dive</td>\n",
       "      <td>16</td>\n",
       "      <td>reactjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314407</th>\n",
       "      <td>TIL about code snippets</td>\n",
       "      <td>82</td>\n",
       "      <td>csharp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589826</th>\n",
       "      <td>anyone else very irritated that Apple has gott...</td>\n",
       "      <td>41</td>\n",
       "      <td>ios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47076</th>\n",
       "      <td>Absolute Beginner!, Getting Started &amp;amp; Ques...</td>\n",
       "      <td>6</td>\n",
       "      <td>linux4noobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454925</th>\n",
       "      <td>[Theme] I'm Time, I'm literally Time</td>\n",
       "      <td>52</td>\n",
       "      <td>androidthemes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432066</th>\n",
       "      <td>Trying to set up VPN + Docker + UFW</td>\n",
       "      <td>9</td>\n",
       "      <td>docker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225283</th>\n",
       "      <td>Front vs Back Fingerprint Sensor.</td>\n",
       "      <td>137</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141334</th>\n",
       "      <td>Looking to make a study team for a free CS maj...</td>\n",
       "      <td>18</td>\n",
       "      <td>computerscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371875</th>\n",
       "      <td>why are apps slow to download?</td>\n",
       "      <td>9</td>\n",
       "      <td>ios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566207</th>\n",
       "      <td>Best distro for a 2006 computer?</td>\n",
       "      <td>6</td>\n",
       "      <td>linux4noobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85162</th>\n",
       "      <td>If you're still holding the home button hoping...</td>\n",
       "      <td>100</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560802</th>\n",
       "      <td>Is public static methods good or bad practice?</td>\n",
       "      <td>17</td>\n",
       "      <td>csharp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440376</th>\n",
       "      <td>Xiaomi confirms their new flagship phone will ...</td>\n",
       "      <td>291</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491103</th>\n",
       "      <td>​ Graph Attach: Simple computational graph lib...</td>\n",
       "      <td>26</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60718</th>\n",
       "      <td>Udemy course: Mosh or Max?</td>\n",
       "      <td>7</td>\n",
       "      <td>Angular2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88067</th>\n",
       "      <td>[UPDATE] Not performing well in new job, what ...</td>\n",
       "      <td>21</td>\n",
       "      <td>cscareerquestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601180</th>\n",
       "      <td>What would you prefer as the second camera in ...</td>\n",
       "      <td>111</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413590</th>\n",
       "      <td>Best way to scrape this data that isn't in the...</td>\n",
       "      <td>10</td>\n",
       "      <td>learnpython</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367971</th>\n",
       "      <td>Bad Data Scientist, no donut</td>\n",
       "      <td>54</td>\n",
       "      <td>datascience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323047</th>\n",
       "      <td>Jobs that require security clearances? How do ...</td>\n",
       "      <td>11</td>\n",
       "      <td>cscareerquestions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  score  \\\n",
       "448227  ReactJs component lifecycle methods — A deep dive     16   \n",
       "314407                            TIL about code snippets     82   \n",
       "589826  anyone else very irritated that Apple has gott...     41   \n",
       "47076   Absolute Beginner!, Getting Started &amp; Ques...      6   \n",
       "454925               [Theme] I'm Time, I'm literally Time     52   \n",
       "432066                Trying to set up VPN + Docker + UFW      9   \n",
       "225283                  Front vs Back Fingerprint Sensor.    137   \n",
       "141334  Looking to make a study team for a free CS maj...     18   \n",
       "371875                     why are apps slow to download?      9   \n",
       "566207                   Best distro for a 2006 computer?      6   \n",
       "85162   If you're still holding the home button hoping...    100   \n",
       "560802     Is public static methods good or bad practice?     17   \n",
       "440376  Xiaomi confirms their new flagship phone will ...    291   \n",
       "491103  ​ Graph Attach: Simple computational graph lib...     26   \n",
       "60718                          Udemy course: Mosh or Max?      7   \n",
       "88067   [UPDATE] Not performing well in new job, what ...     21   \n",
       "601180  What would you prefer as the second camera in ...    111   \n",
       "413590  Best way to scrape this data that isn't in the...     10   \n",
       "367971                       Bad Data Scientist, no donut     54   \n",
       "323047  Jobs that require security clearances? How do ...     11   \n",
       "\n",
       "                subreddit  \n",
       "448227            reactjs  \n",
       "314407             csharp  \n",
       "589826                ios  \n",
       "47076         linux4noobs  \n",
       "454925      androidthemes  \n",
       "432066             docker  \n",
       "225283            Android  \n",
       "141334    computerscience  \n",
       "371875                ios  \n",
       "566207        linux4noobs  \n",
       "85162             Android  \n",
       "560802             csharp  \n",
       "440376            Android  \n",
       "491103             Python  \n",
       "60718            Angular2  \n",
       "88067   cscareerquestions  \n",
       "601180            Android  \n",
       "413590        learnpython  \n",
       "367971        datascience  \n",
       "323047  cscareerquestions  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_data['title']\n",
    "y = filtered_data['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data into train (60%), val (20%), and test (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59364,)\n",
      "(19788,)\n",
      "(19789,)\n",
      "(59364,)\n",
      "(19788,)\n",
      "(19789,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=17)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=31)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Baseline\n",
    "Simple baseline using tf-idf based approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data['subreddit'])\n",
    "\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_val_vectors = vectorizer.transform(X_val)\n",
    "X_test_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def top_n_accuracy(y_true, probs, n=5):\n",
    "    top_n_list = []\n",
    "    for prob in probs:\n",
    "        top_n_list.append(np.argsort(-prob)[:n])\n",
    "    predictions = []\n",
    "    for prediction, top_n in zip(y_true, top_n_list):\n",
    "        predictions.append(int(prediction in top_n))\n",
    "    return np.sum(predictions) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = nb.predict(X_val_vectors)\n",
    "nb_probs = nb.predict_proba(X_val_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy:\n",
      " 0.288392541311\n",
      "Top 5 accuracy:\n",
      " 0.592298751832\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.17      0.99      0.28      1362\n",
      "          1       0.73      0.32      0.44       180\n",
      "          2       0.00      0.00      0.00       105\n",
      "          3       0.56      0.02      0.04       216\n",
      "          4       1.00      0.02      0.03       125\n",
      "          5       0.00      0.00      0.00        91\n",
      "          6       1.00      0.10      0.18       101\n",
      "          7       0.00      0.00      0.00        69\n",
      "          8       0.00      0.00      0.00        18\n",
      "          9       1.00      0.01      0.02        89\n",
      "         10       0.00      0.00      0.00        18\n",
      "         11       0.00      0.00      0.00        38\n",
      "         12       0.00      0.00      0.00       115\n",
      "         13       0.00      0.00      0.00        13\n",
      "         14       0.00      0.00      0.00        19\n",
      "         15       0.00      0.00      0.00        20\n",
      "         16       0.00      0.00      0.00        52\n",
      "         17       0.41      0.09      0.15       391\n",
      "         18       0.52      0.04      0.07       307\n",
      "         19       0.50      0.01      0.02        88\n",
      "         20       0.00      0.00      0.00        49\n",
      "         21       0.00      0.00      0.00        47\n",
      "         22       0.52      0.40      0.45       486\n",
      "         23       0.69      0.23      0.34       393\n",
      "         24       0.95      0.38      0.54       327\n",
      "         25       1.00      0.02      0.05        82\n",
      "         26       0.93      0.28      0.43       252\n",
      "         27       0.87      0.14      0.24       184\n",
      "         28       0.81      0.44      0.57       309\n",
      "         29       0.00      0.00      0.00        59\n",
      "         30       0.00      0.00      0.00        33\n",
      "         31       0.66      0.32      0.44       305\n",
      "         32       0.00      0.00      0.00        62\n",
      "         33       0.00      0.00      0.00       102\n",
      "         34       0.00      0.00      0.00        64\n",
      "         35       0.00      0.00      0.00        95\n",
      "         36       0.00      0.00      0.00        62\n",
      "         37       1.00      0.01      0.01       151\n",
      "         38       0.00      0.00      0.00        57\n",
      "         39       0.00      0.00      0.00        95\n",
      "         40       1.00      0.05      0.09       181\n",
      "         41       0.00      0.00      0.00         8\n",
      "         42       0.00      0.00      0.00        89\n",
      "         43       0.30      0.88      0.45       747\n",
      "         44       0.50      0.01      0.02       166\n",
      "         45       1.00      0.01      0.02       107\n",
      "         46       0.92      0.48      0.63       227\n",
      "         47       0.00      0.00      0.00         9\n",
      "         48       0.00      0.00      0.00        14\n",
      "         49       0.96      0.29      0.45       167\n",
      "         50       0.65      0.11      0.19       219\n",
      "         51       0.00      0.00      0.00        90\n",
      "         52       1.00      0.04      0.08       118\n",
      "         53       0.00      0.00      0.00        26\n",
      "         54       0.94      0.14      0.24       115\n",
      "         55       0.67      0.28      0.39       161\n",
      "         56       1.00      0.02      0.04        51\n",
      "         57       0.00      0.00      0.00        72\n",
      "         58       0.00      0.00      0.00        11\n",
      "         59       1.00      0.02      0.04        49\n",
      "         60       0.00      0.00      0.00        59\n",
      "         61       0.00      0.00      0.00        42\n",
      "         62       0.83      0.05      0.09       209\n",
      "         63       0.45      0.12      0.19       542\n",
      "         64       0.91      0.22      0.36       224\n",
      "         65       0.00      0.00      0.00        28\n",
      "         66       0.00      0.00      0.00        67\n",
      "         67       0.65      0.71      0.68       500\n",
      "         68       0.45      0.08      0.14       255\n",
      "         69       0.58      0.02      0.04       331\n",
      "         70       0.00      0.00      0.00        36\n",
      "         71       0.65      0.38      0.48       335\n",
      "         72       0.41      0.05      0.09       267\n",
      "         73       0.32      0.26      0.29       374\n",
      "         74       0.00      0.00      0.00        51\n",
      "         75       1.00      0.02      0.03       124\n",
      "         76       0.00      0.00      0.00       102\n",
      "         77       0.25      0.07      0.11       396\n",
      "         78       0.21      0.72      0.33       605\n",
      "         79       0.57      0.13      0.21       397\n",
      "         80       0.30      0.01      0.03       420\n",
      "         81       0.00      0.00      0.00        69\n",
      "         82       0.23      0.77      0.35       734\n",
      "         83       0.00      0.00      0.00        24\n",
      "         84       0.71      0.14      0.23       213\n",
      "         85       0.00      0.00      0.00        38\n",
      "         86       0.00      0.00      0.00        38\n",
      "         87       0.00      0.00      0.00        52\n",
      "         88       0.84      0.43      0.57       412\n",
      "         89       0.00      0.00      0.00        27\n",
      "         90       0.81      0.14      0.24       183\n",
      "         91       0.00      0.00      0.00        20\n",
      "         92       0.00      0.00      0.00       114\n",
      "         93       0.00      0.00      0.00        31\n",
      "         94       0.00      0.00      0.00        87\n",
      "         95       0.71      0.07      0.12        74\n",
      "         96       0.00      0.00      0.00        21\n",
      "         97       0.75      0.02      0.04       149\n",
      "         98       0.84      0.31      0.45       227\n",
      "         99       0.67      0.24      0.35       226\n",
      "        100       0.00      0.00      0.00        14\n",
      "        101       0.00      0.00      0.00        12\n",
      "        102       0.56      0.07      0.13       140\n",
      "        103       0.00      0.00      0.00        16\n",
      "        104       0.86      0.46      0.60       295\n",
      "        105       1.00      0.03      0.07        89\n",
      "        106       0.00      0.00      0.00        30\n",
      "        107       0.58      0.04      0.08       313\n",
      "        108       0.80      0.06      0.11       136\n",
      "        109       0.00      0.00      0.00        19\n",
      "        110       0.00      0.00      0.00        23\n",
      "        111       0.23      0.01      0.02       269\n",
      "        112       0.16      0.28      0.20       551\n",
      "        113       0.57      0.11      0.19       444\n",
      "        114       0.00      0.00      0.00        28\n",
      "        115       0.00      0.00      0.00        33\n",
      "        116       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.48      0.29      0.24     19789\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victorkwak/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Top 1 accuracy:\\n', top_n_accuracy(y_val, nb_probs, 1))\n",
    "print('Top 5 accuracy:\\n', top_n_accuracy(y_val, nb_probs, 5))\n",
    "print(classification_report(y_val, nb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC(penalty='l2', loss='squared_hinge', multi_class='ovr', max_iter=1000)\n",
    "svm.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.501288594674\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.87      0.80      1362\n",
      "          1       0.64      0.69      0.67       180\n",
      "          2       0.18      0.10      0.13       105\n",
      "          3       0.36      0.31      0.33       216\n",
      "          4       0.47      0.50      0.48       125\n",
      "          5       0.19      0.15      0.17        91\n",
      "          6       0.81      0.70      0.75       101\n",
      "          7       0.25      0.20      0.22        69\n",
      "          8       0.50      0.06      0.10        18\n",
      "          9       0.65      0.62      0.64        89\n",
      "         10       0.88      0.78      0.82        18\n",
      "         11       0.45      0.37      0.41        38\n",
      "         12       0.61      0.46      0.52       115\n",
      "         13       0.60      0.23      0.33        13\n",
      "         14       0.88      0.74      0.80        19\n",
      "         15       0.33      0.05      0.09        20\n",
      "         16       0.65      0.60      0.62        52\n",
      "         17       0.23      0.30      0.26       391\n",
      "         18       0.40      0.30      0.34       307\n",
      "         19       0.60      0.57      0.58        88\n",
      "         20       0.35      0.37      0.36        49\n",
      "         21       0.06      0.02      0.03        47\n",
      "         22       0.47      0.54      0.50       486\n",
      "         23       0.58      0.54      0.56       393\n",
      "         24       0.65      0.61      0.63       327\n",
      "         25       0.37      0.32      0.34        82\n",
      "         26       0.70      0.64      0.67       252\n",
      "         27       0.65      0.68      0.67       184\n",
      "         28       0.75      0.78      0.77       309\n",
      "         29       0.24      0.20      0.22        59\n",
      "         30       0.30      0.21      0.25        33\n",
      "         31       0.55      0.72      0.62       305\n",
      "         32       0.36      0.15      0.21        62\n",
      "         33       0.04      0.02      0.03       102\n",
      "         34       0.21      0.14      0.17        64\n",
      "         35       0.14      0.08      0.10        95\n",
      "         36       0.59      0.37      0.46        62\n",
      "         37       0.21      0.19      0.20       151\n",
      "         38       0.44      0.32      0.37        57\n",
      "         39       0.10      0.06      0.08        95\n",
      "         40       0.58      0.46      0.51       181\n",
      "         41       0.00      0.00      0.00         8\n",
      "         42       0.55      0.48      0.51        89\n",
      "         43       0.51      0.69      0.59       747\n",
      "         44       0.21      0.16      0.18       166\n",
      "         45       0.35      0.42      0.38       107\n",
      "         46       0.69      0.82      0.75       227\n",
      "         47       0.50      0.44      0.47         9\n",
      "         48       0.90      0.64      0.75        14\n",
      "         49       0.83      0.81      0.82       167\n",
      "         50       0.51      0.52      0.51       219\n",
      "         51       0.54      0.49      0.51        90\n",
      "         52       0.68      0.68      0.68       118\n",
      "         53       0.00      0.00      0.00        26\n",
      "         54       0.71      0.64      0.68       115\n",
      "         55       0.49      0.49      0.49       161\n",
      "         56       0.91      0.78      0.84        51\n",
      "         57       0.57      0.39      0.46        72\n",
      "         58       0.69      0.82      0.75        11\n",
      "         59       0.59      0.69      0.64        49\n",
      "         60       0.48      0.58      0.52        59\n",
      "         61       0.23      0.26      0.25        42\n",
      "         62       0.44      0.36      0.40       209\n",
      "         63       0.34      0.31      0.33       542\n",
      "         64       0.70      0.65      0.67       224\n",
      "         65       0.17      0.04      0.06        28\n",
      "         66       0.29      0.25      0.27        67\n",
      "         67       0.76      0.93      0.84       500\n",
      "         68       0.43      0.38      0.41       255\n",
      "         69       0.47      0.52      0.49       331\n",
      "         70       0.62      0.14      0.23        36\n",
      "         71       0.57      0.65      0.61       335\n",
      "         72       0.28      0.30      0.29       267\n",
      "         73       0.36      0.38      0.37       374\n",
      "         74       0.44      0.35      0.39        51\n",
      "         75       0.84      0.65      0.73       124\n",
      "         76       0.19      0.13      0.15       102\n",
      "         77       0.24      0.19      0.21       396\n",
      "         78       0.38      0.53      0.44       605\n",
      "         79       0.45      0.45      0.45       397\n",
      "         80       0.23      0.20      0.21       420\n",
      "         81       0.18      0.09      0.12        69\n",
      "         82       0.39      0.45      0.42       734\n",
      "         83       0.90      0.75      0.82        24\n",
      "         84       0.50      0.59      0.54       213\n",
      "         85       0.26      0.13      0.18        38\n",
      "         86       0.73      0.58      0.65        38\n",
      "         87       0.45      0.42      0.44        52\n",
      "         88       0.64      0.69      0.66       412\n",
      "         89       0.44      0.44      0.44        27\n",
      "         90       0.49      0.55      0.52       183\n",
      "         91       0.25      0.05      0.08        20\n",
      "         92       0.25      0.18      0.21       114\n",
      "         93       0.75      0.58      0.65        31\n",
      "         94       0.26      0.17      0.21        87\n",
      "         95       0.69      0.61      0.65        74\n",
      "         96       0.83      0.48      0.61        21\n",
      "         97       0.52      0.45      0.48       149\n",
      "         98       0.71      0.69      0.70       227\n",
      "         99       0.65      0.72      0.68       226\n",
      "        100       0.73      0.57      0.64        14\n",
      "        101       0.00      0.00      0.00        12\n",
      "        102       0.68      0.56      0.62       140\n",
      "        103       0.00      0.00      0.00        16\n",
      "        104       0.76      0.78      0.77       295\n",
      "        105       0.83      0.71      0.76        89\n",
      "        106       0.12      0.10      0.11        30\n",
      "        107       0.29      0.33      0.31       313\n",
      "        108       0.51      0.45      0.48       136\n",
      "        109       0.90      1.00      0.95        19\n",
      "        110       0.80      0.52      0.63        23\n",
      "        111       0.28      0.28      0.28       269\n",
      "        112       0.24      0.18      0.21       551\n",
      "        113       0.42      0.41      0.41       444\n",
      "        114       0.67      0.14      0.24        28\n",
      "        115       0.36      0.30      0.33        33\n",
      "        116       0.78      0.44      0.56        16\n",
      "\n",
      "avg / total       0.49      0.50      0.49     19789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_predictions = svm.predict(X_val_vectors)\n",
    "\n",
    "print(accuracy_score(y_val, svm_predictions))\n",
    "print(classification_report(y_val, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "\n",
    "tagged_documents = []\n",
    "tokens = None\n",
    "for text, label in zip(X_train, y_train):\n",
    "    text = text.lower()\n",
    "    tokens = utils.simple_preprocess(text)\n",
    "    tagged_documents.append(TaggedDocument(tokens, [label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['lessons', 'learned', 'from', 'my', 'latest', 'game', 'iteration', 'from', 'stars', 'to', 'over'], tags=[71]),\n",
       " TaggedDocument(words=['little', 'asp', 'net', 'core', 'book'], tags=[112]),\n",
       " TaggedDocument(words=['responsive', 'background', 'images', 'with', 'javascript'], tags=[111]),\n",
       " TaggedDocument(words=['can', 'ssh', 'to', 'virtual', 'machine', 'when', 'ipv', 'is', 'set', 'to', 'automatic', 'dhcp', 'but', 'can', 'ssh', 'when', 'use', 'manual', 'and', 'input', 'my', 'own', 'addresses'], tags=[82]),\n",
       " TaggedDocument(words=['conversational', 'dataset'], tags=[51])]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(size=64, window=7, min_count=1, workers=4, iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10405265"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build_vocab(tagged_documents)\n",
    "model.train(tagged_documents, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors = X_train.map(lambda title: model.infer_vector(utils.simple_preprocess(title))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors = np.array(list(X_train_vectors), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59364, 64)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC(penalty='l2', loss='squared_hinge', multi_class='ovr', max_iter=1000)\n",
    "svm.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_vectors = X_val.map(lambda title: model.infer_vector(utils.simple_preprocess(title))).values\n",
    "X_val_vectors = np.array(list(X_val_vectors), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predictions = svm.predict(X_val_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.295416645611\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.31      0.66      0.42      1362\n",
      "          1       0.54      0.74      0.62       180\n",
      "          2       0.00      0.00      0.00       105\n",
      "          3       0.29      0.07      0.11       216\n",
      "          4       0.45      0.11      0.18       125\n",
      "          5       0.00      0.00      0.00        91\n",
      "          6       0.56      0.54      0.55       101\n",
      "          7       0.00      0.00      0.00        69\n",
      "          8       0.00      0.00      0.00        18\n",
      "          9       0.27      0.26      0.26        89\n",
      "         10       0.00      0.00      0.00        18\n",
      "         11       0.00      0.00      0.00        38\n",
      "         12       0.29      0.03      0.06       115\n",
      "         13       0.00      0.00      0.00        13\n",
      "         14       0.00      0.00      0.00        19\n",
      "         15       0.00      0.00      0.00        20\n",
      "         16       0.67      0.04      0.07        52\n",
      "         17       0.10      0.07      0.08       391\n",
      "         18       0.32      0.23      0.27       307\n",
      "         19       0.23      0.03      0.06        88\n",
      "         20       0.00      0.00      0.00        49\n",
      "         21       0.00      0.00      0.00        47\n",
      "         22       0.22      0.30      0.25       486\n",
      "         23       0.21      0.29      0.25       393\n",
      "         24       0.28      0.54      0.36       327\n",
      "         25       0.00      0.00      0.00        82\n",
      "         26       0.36      0.58      0.45       252\n",
      "         27       0.36      0.52      0.43       184\n",
      "         28       0.35      0.59      0.44       309\n",
      "         29       0.00      0.00      0.00        59\n",
      "         30       0.00      0.00      0.00        33\n",
      "         31       0.30      0.37      0.33       305\n",
      "         32       0.00      0.00      0.00        62\n",
      "         33       0.00      0.00      0.00       102\n",
      "         34       0.00      0.00      0.00        64\n",
      "         35       0.00      0.00      0.00        95\n",
      "         36       0.00      0.00      0.00        62\n",
      "         37       0.00      0.00      0.00       151\n",
      "         38       0.00      0.00      0.00        57\n",
      "         39       0.00      0.00      0.00        95\n",
      "         40       0.35      0.17      0.22       181\n",
      "         41       0.00      0.00      0.00         8\n",
      "         42       0.52      0.12      0.20        89\n",
      "         43       0.21      0.35      0.26       747\n",
      "         44       0.00      0.00      0.00       166\n",
      "         45       0.27      0.14      0.19       107\n",
      "         46       0.35      0.63      0.45       227\n",
      "         47       0.00      0.00      0.00         9\n",
      "         48       0.00      0.00      0.00        14\n",
      "         49       0.42      0.69      0.52       167\n",
      "         50       0.11      0.01      0.02       219\n",
      "         51       0.27      0.23      0.25        90\n",
      "         52       0.58      0.53      0.56       118\n",
      "         53       0.00      0.00      0.00        26\n",
      "         54       0.45      0.39      0.42       115\n",
      "         55       0.36      0.16      0.22       161\n",
      "         56       0.65      0.47      0.55        51\n",
      "         57       0.00      0.00      0.00        72\n",
      "         58       0.00      0.00      0.00        11\n",
      "         59       0.52      0.45      0.48        49\n",
      "         60       0.29      0.41      0.34        59\n",
      "         61       0.00      0.00      0.00        42\n",
      "         62       0.39      0.65      0.49       209\n",
      "         63       0.16      0.18      0.17       542\n",
      "         64       0.45      0.54      0.49       224\n",
      "         65       0.00      0.00      0.00        28\n",
      "         66       0.00      0.00      0.00        67\n",
      "         67       0.35      0.70      0.47       500\n",
      "         68       0.26      0.07      0.11       255\n",
      "         69       0.29      0.28      0.28       331\n",
      "         70       0.00      0.00      0.00        36\n",
      "         71       0.30      0.54      0.38       335\n",
      "         72       0.24      0.04      0.08       267\n",
      "         73       0.23      0.26      0.24       374\n",
      "         74       0.00      0.00      0.00        51\n",
      "         75       0.54      0.59      0.56       124\n",
      "         76       0.00      0.00      0.00       102\n",
      "         77       0.15      0.01      0.01       396\n",
      "         78       0.19      0.29      0.23       605\n",
      "         79       0.23      0.28      0.26       397\n",
      "         80       0.14      0.02      0.03       420\n",
      "         81       0.00      0.00      0.00        69\n",
      "         82       0.19      0.32      0.24       734\n",
      "         83       0.64      0.29      0.40        24\n",
      "         84       0.31      0.43      0.36       213\n",
      "         85       0.00      0.00      0.00        38\n",
      "         86       0.55      0.29      0.38        38\n",
      "         87       0.25      0.02      0.04        52\n",
      "         88       0.29      0.58      0.39       412\n",
      "         89       0.00      0.00      0.00        27\n",
      "         90       0.38      0.08      0.13       183\n",
      "         91       0.00      0.00      0.00        20\n",
      "         92       0.00      0.00      0.00       114\n",
      "         93       0.73      0.26      0.38        31\n",
      "         94       0.00      0.00      0.00        87\n",
      "         95       0.40      0.53      0.45        74\n",
      "         96       0.50      0.10      0.16        21\n",
      "         97       0.50      0.28      0.36       149\n",
      "         98       0.27      0.19      0.23       227\n",
      "         99       0.41      0.53      0.46       226\n",
      "        100       0.00      0.00      0.00        14\n",
      "        101       0.00      0.00      0.00        12\n",
      "        102       0.47      0.48      0.47       140\n",
      "        103       0.00      0.00      0.00        16\n",
      "        104       0.44      0.68      0.53       295\n",
      "        105       0.52      0.48      0.50        89\n",
      "        106       0.00      0.00      0.00        30\n",
      "        107       0.12      0.03      0.05       313\n",
      "        108       0.35      0.38      0.36       136\n",
      "        109       1.00      0.16      0.27        19\n",
      "        110       0.00      0.00      0.00        23\n",
      "        111       0.19      0.06      0.09       269\n",
      "        112       0.10      0.04      0.05       551\n",
      "        113       0.33      0.19      0.24       444\n",
      "        114       0.00      0.00      0.00        28\n",
      "        115       0.00      0.00      0.00        33\n",
      "        116       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.25      0.30      0.25     19789\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victorkwak/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_val, svm_predictions))\n",
    "print(classification_report(y_val, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH_STOP_WORDS = frozenset([\n",
    "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
    "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
    "    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
    "    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
    "    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
    "    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
    "    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
    "    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\",\n",
    "    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
    "    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
    "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
    "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
    "    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
    "    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
    "    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
    "    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
    "    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
    "    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
    "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
    "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
    "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
    "    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
    "    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
    "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
    "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
    "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
    "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "\"yourselves\"])\n",
    "\n",
    "\n",
    "def format_for_fastext(X, y, filename):\n",
    "    prefix = '__label__'\n",
    "    f = open(''.join(['data/', filename]), 'w')\n",
    "    for title, label in zip(X, y):\n",
    "        title = title.lower()\n",
    "        tokens = utils.simple_preprocess(title)\n",
    "        tokens = [token for token in tokens if token not in ENGLISH_STOP_WORDS]\n",
    "        f.write(''.join([prefix, str(label), ' ', ' '.join(tokens), '\\n']))\n",
    "    f.close()\n",
    "    \n",
    "format_for_fastext(X_train, y_train, 'reddit_fasttext_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fasttext(y, X, classifier, n=1):\n",
    "    match = []\n",
    "    for true, string in zip(y, X):\n",
    "        predictions = list(classifier.predict(string, n)[0])\n",
    "        for i in range(n):\n",
    "            predictions[i] = int(predictions[i].split('__label__')[1])\n",
    "        match.append(int(true in predictions))\n",
    "    return np.array(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31982414472686849"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastText\n",
    "\n",
    "classifier = fastText.train_supervised(input='data/reddit_fasttext_train.txt',\n",
    "                                 lr=0.1,\n",
    "                                 epoch=30,\n",
    "                                 dim=64,\n",
    "                                 minn=2,\n",
    "                                 maxn=5\n",
    "                                )\n",
    "\n",
    "correct = test_fasttext(y_val, X_val, classifier)\n",
    "correct.sum() / y_val.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save_model('models/fasttext.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastText import load_model\n",
    "\n",
    "classifier = load_model('models/fasttext.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78822616275598545"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = test_fasttext(y_val, X_val, classifier, 10)\n",
    "correct.sum() / y_val.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66738312735088667"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = test_fasttext(y_val, X_val, classifier, 5)\n",
    "correct.sum() / y_val.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
