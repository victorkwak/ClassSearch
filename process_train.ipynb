{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/cs_subs.csv')  # unzip this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['subreddit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624289, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624281, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Android                61202\n",
       "learnprogramming       35288\n",
       "cscareerquestions      32935\n",
       "Windows10              27726\n",
       "webdev                 26849\n",
       "dataisbeautiful        24388\n",
       "softwaregore           23741\n",
       "web_design             22159\n",
       "ProgrammerHumor        19206\n",
       "learnpython            17634\n",
       "raspberry_pi           15659\n",
       "iOSBeta                14508\n",
       "linux                  14058\n",
       "javascript             12971\n",
       "linuxquestions         11464\n",
       "hackernews             11134\n",
       "Python                 11119\n",
       "windows                10132\n",
       "androiddev             10130\n",
       "mac                     9841\n",
       "ios                     9754\n",
       "arduino                 9603\n",
       "java                    9401\n",
       "networking              9378\n",
       "linux4noobs             8004\n",
       "androidthemes           7895\n",
       "chrome                  5862\n",
       "iOSProgramming          5647\n",
       "rust                    5489\n",
       "datascience             5374\n",
       "                       ...  \n",
       "redis                    241\n",
       "dartlang                 240\n",
       "programmerreactions      237\n",
       "Julia                    217\n",
       "reviewmycode             216\n",
       "zsh                      210\n",
       "OSXTweaks                198\n",
       "erlang                   186\n",
       "MaterialDesign           179\n",
       "d3js                     179\n",
       "npm                      164\n",
       "c_language               143\n",
       "learnphp                 120\n",
       "Heroku                   118\n",
       "dailyprogrammer          114\n",
       "cakephp                  113\n",
       "learnruby                106\n",
       "mariadb                   95\n",
       "tinycode                  93\n",
       "groovy                    90\n",
       "pythoncoding              88\n",
       "vagrant                   77\n",
       "Cprog                     38\n",
       "androiddesign             36\n",
       "osxterminal               31\n",
       "learnlaravel              28\n",
       "shell                     24\n",
       "haskelltil                24\n",
       "dotfiles                  17\n",
       "AskCompSci                17\n",
       "Name: subreddit, Length: 136, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423610</th>\n",
       "      <td>I found this article in an old magazine and ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>ProgrammerHumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176128</th>\n",
       "      <td>My Rust server</td>\n",
       "      <td>1</td>\n",
       "      <td>rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350321</th>\n",
       "      <td>Free Club Music Player App</td>\n",
       "      <td>0</td>\n",
       "      <td>macapps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11928</th>\n",
       "      <td>Anti-virus software is just a terrible idea, w...</td>\n",
       "      <td>1</td>\n",
       "      <td>windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584377</th>\n",
       "      <td>Introducing the Windows Console Colortool</td>\n",
       "      <td>64</td>\n",
       "      <td>Windows10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445763</th>\n",
       "      <td>How to create custom number pad keyboard in an...</td>\n",
       "      <td>3</td>\n",
       "      <td>androiddev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156759</th>\n",
       "      <td>Discord: Stoked to announce our super sick app...</td>\n",
       "      <td>142</td>\n",
       "      <td>linux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237445</th>\n",
       "      <td>Not a shill but cracked.com is offering discou...</td>\n",
       "      <td>1</td>\n",
       "      <td>learnprogramming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294108</th>\n",
       "      <td>[Review] Samsung Galaxy Jet and its 800 MHz pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252857</th>\n",
       "      <td>Getting a CS degree at.. late age (long and so...</td>\n",
       "      <td>0</td>\n",
       "      <td>cscareerquestions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  score  \\\n",
       "423610  I found this article in an old magazine and ha...      1   \n",
       "176128                                     My Rust server      1   \n",
       "350321                         Free Club Music Player App      0   \n",
       "11928   Anti-virus software is just a terrible idea, w...      1   \n",
       "584377          Introducing the Windows Console Colortool     64   \n",
       "445763  How to create custom number pad keyboard in an...      3   \n",
       "156759  Discord: Stoked to announce our super sick app...    142   \n",
       "237445  Not a shill but cracked.com is offering discou...      1   \n",
       "294108  [Review] Samsung Galaxy Jet and its 800 MHz pr...      1   \n",
       "252857  Getting a CS degree at.. late age (long and so...      0   \n",
       "\n",
       "                subreddit  \n",
       "423610    ProgrammerHumor  \n",
       "176128               rust  \n",
       "350321            macapps  \n",
       "11928             windows  \n",
       "584377          Windows10  \n",
       "445763         androiddev  \n",
       "156759              linux  \n",
       "237445   learnprogramming  \n",
       "294108            Android  \n",
       "252857  cscareerquestions  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are filtering non-latin words, and also subreddits that have less than 150 posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data['subreddit'].value_counts()\n",
    "counts = counts[counts > 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_values = list(counts.index)\n",
    "data = data[data['subreddit'].isin(top_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Android                61202\n",
       "learnprogramming       35288\n",
       "cscareerquestions      32935\n",
       "Windows10              27726\n",
       "webdev                 26849\n",
       "dataisbeautiful        24388\n",
       "softwaregore           23741\n",
       "web_design             22159\n",
       "ProgrammerHumor        19206\n",
       "learnpython            17634\n",
       "raspberry_pi           15659\n",
       "iOSBeta                14508\n",
       "linux                  14058\n",
       "javascript             12971\n",
       "linuxquestions         11464\n",
       "hackernews             11134\n",
       "Python                 11119\n",
       "windows                10132\n",
       "androiddev             10130\n",
       "mac                     9841\n",
       "ios                     9754\n",
       "arduino                 9603\n",
       "java                    9401\n",
       "networking              9378\n",
       "linux4noobs             8004\n",
       "androidthemes           7895\n",
       "chrome                  5862\n",
       "iOSProgramming          5647\n",
       "rust                    5489\n",
       "datascience             5374\n",
       "                       ...  \n",
       "windowsinsiders          683\n",
       "jquery                   667\n",
       "operabrowser             647\n",
       "browsers                 586\n",
       "watchOSBeta              581\n",
       "LanguageTechnology       528\n",
       "macapps                  526\n",
       "mongodb                  507\n",
       "rubyonrails              455\n",
       "itsaunixsystem           449\n",
       "djangolearning           428\n",
       "nginx                    420\n",
       "haskellquestions         394\n",
       "lua                      363\n",
       "symfony                  357\n",
       "windows8                 334\n",
       "cprogramming             328\n",
       "Meteor                   316\n",
       "DatabaseHelp             312\n",
       "redis                    241\n",
       "dartlang                 240\n",
       "programmerreactions      237\n",
       "Julia                    217\n",
       "reviewmycode             216\n",
       "zsh                      210\n",
       "OSXTweaks                198\n",
       "erlang                   186\n",
       "MaterialDesign           179\n",
       "d3js                     179\n",
       "npm                      164\n",
       "Name: subreddit, Length: 117, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622909, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of data. Especially for my Macbook. Let's see the average reddit score (upvotes + downvotes) for each subreddit to filter out. I want to do mean and not median since median would just arbitrarily cut the data in half. Hopefully filtering by mean will take relatively larger chunks out of the more popular subreddits than the less popular ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = {}\n",
    "for subreddit in data['subreddit'].unique():\n",
    "    means[subreddit] = data[data['subreddit'] == subreddit]['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Android': 75.0088722590765,\n",
       " 'Angular2': 5.473166368515206,\n",
       " 'AskComputerScience': 4.370666666666667,\n",
       " 'AskNetsec': 6.923273657289003,\n",
       " 'AutoHotkey': 1.8294736842105264,\n",
       " 'C_Programming': 6.593274988484569,\n",
       " 'Clojure': 17.862068965517242,\n",
       " 'Database': 2.3162813575996064,\n",
       " 'DatabaseHelp': 1.2147435897435896,\n",
       " 'IOT': 1.9538461538461538,\n",
       " 'Julia': 11.55299539170507,\n",
       " 'LanguageTechnology': 5.160984848484849,\n",
       " 'MLQuestions': 2.3911630929174787,\n",
       " 'MaterialDesign': 10.139664804469273,\n",
       " 'Meteor': 3.731012658227848,\n",
       " 'OSXTweaks': 4.51010101010101,\n",
       " 'PostgreSQL': 6.54421768707483,\n",
       " 'ProgrammerHumor': 460.36457357075915,\n",
       " 'Python': 19.62010972209731,\n",
       " 'SQLServer': 3.208778173190985,\n",
       " 'UI_Design': 4.922300706357215,\n",
       " 'Web_Development': 1.165680473372781,\n",
       " 'Windows10': 14.500180336146578,\n",
       " 'androiddev': 11.89121421520237,\n",
       " 'androidthemes': 30.770867637745408,\n",
       " 'angularjs': 5.399414776883687,\n",
       " 'arduino': 12.679683432260752,\n",
       " 'artificial': 7.961448293826518,\n",
       " 'aws': 6.961463223787168,\n",
       " 'bash': 4.618069815195072,\n",
       " 'browsers': 1.8754266211604096,\n",
       " 'chrome': 5.607130672125554,\n",
       " 'chrome_extensions': 2.472513089005236,\n",
       " 'coding': 13.21768140116764,\n",
       " 'commandline': 18.727650727650726,\n",
       " 'compsci': 21.0,\n",
       " 'computerforensics': 6.737995824634655,\n",
       " 'computerscience': 5.429937355753379,\n",
       " 'computervision': 4.359840954274354,\n",
       " 'coolgithubprojects': 10.124707259953162,\n",
       " 'cpp': 21.44868469803631,\n",
       " 'cprogramming': 1.298780487804878,\n",
       " 'crypto': 11.673133450911228,\n",
       " 'cscareerquestions': 9.30821314710794,\n",
       " 'csharp': 11.75581084691424,\n",
       " 'css': 5.632745364088648,\n",
       " 'csshelp': 1.5042659605766402,\n",
       " 'd3js': 3.335195530726257,\n",
       " 'dartlang': 10.729166666666666,\n",
       " 'dataisbeautiful': 316.7866983762506,\n",
       " 'datascience': 8.189430591737997,\n",
       " 'datasets': 7.213797035347777,\n",
       " 'django': 5.676748582230624,\n",
       " 'djangolearning': 1.8808411214953271,\n",
       " 'docker': 5.943201376936317,\n",
       " 'dotnet': 10.152072072072071,\n",
       " 'elixir': 14.012224938875306,\n",
       " 'embedded': 2.9100091827364554,\n",
       " 'erlang': 7.833333333333333,\n",
       " 'flask': 4.382978723404255,\n",
       " 'git': 7.203438395415473,\n",
       " 'github': 3.315450643776824,\n",
       " 'golang': 13.324040219378428,\n",
       " 'hackernews': 4.136428956349919,\n",
       " 'haskell': 24.44258453297623,\n",
       " 'haskellquestions': 3.0761421319796955,\n",
       " 'html5': 2.8614173228346456,\n",
       " 'iOSBeta': 11.140887786049076,\n",
       " 'iOSProgramming': 6.810341774393483,\n",
       " 'ios': 7.587656346114414,\n",
       " 'itsaunixsystem': 169.52783964365256,\n",
       " 'java': 6.7981065844059145,\n",
       " 'javahelp': 2.0778629115758958,\n",
       " 'javascript': 11.282553388327809,\n",
       " 'jquery': 2.8545727136431784,\n",
       " 'laravel': 5.533137583892618,\n",
       " 'learnjava': 3.8305837563451774,\n",
       " 'learnprogramming': 11.639112446157334,\n",
       " 'learnpython': 5.545083361687649,\n",
       " 'linux': 62.09816474605207,\n",
       " 'linux4noobs': 5.7166416791604195,\n",
       " 'linuxmemes': 114.78265765765765,\n",
       " 'linuxquestions': 3.863049546406141,\n",
       " 'lua': 3.961432506887052,\n",
       " 'mac': 6.823290316024794,\n",
       " 'macapps': 10.901140684410647,\n",
       " 'mongodb': 2.6942800788954635,\n",
       " 'mysql': 2.0155902004454345,\n",
       " 'networking': 9.80251652804436,\n",
       " 'nginx': 2.538095238095238,\n",
       " 'node': 8.397439054420094,\n",
       " 'npm': 1.8414634146341464,\n",
       " 'opensource': 15.785149535922997,\n",
       " 'operabrowser': 2.7156105100463677,\n",
       " 'osx': 5.668396770472895,\n",
       " 'perl': 7.4260948905109485,\n",
       " 'programmerreactions': 56.29535864978903,\n",
       " 'rails': 4.292520035618878,\n",
       " 'raspberry_pi': 29.78785363050003,\n",
       " 'reactjs': 10.00154423119347,\n",
       " 'redis': 2.887966804979253,\n",
       " 'reviewmycode': 1.2407407407407407,\n",
       " 'ruby': 10.942513368983958,\n",
       " 'rubyonrails': 2.523076923076923,\n",
       " 'rust': 30.038804882492258,\n",
       " 'scala': 12.583864118895965,\n",
       " 'softwaredevelopment': 1.2789339174881345,\n",
       " 'softwaregore': 112.0459121351249,\n",
       " 'swift': 7.778955954323002,\n",
       " 'symfony': 3.518207282913165,\n",
       " 'watchOSBeta': 4.235800344234079,\n",
       " 'web_design': 9.068685409991426,\n",
       " 'webdev': 13.224179671496145,\n",
       " 'windows': 7.781188314251875,\n",
       " 'windows8': 1.5598802395209581,\n",
       " 'windowsinsiders': 6.093704245973646,\n",
       " 'zsh': 3.4857142857142858}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "filtered = []\n",
    "\n",
    "for subreddit in data['subreddit'].unique():\n",
    "    filtered.append(data.loc[(data['subreddit'] == subreddit) & (data['score'] >= means[subreddit])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = pd.concat(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Android                6807\n",
       "linuxquestions         3893\n",
       "cscareerquestions      3772\n",
       "learnpython            3081\n",
       "webdev                 2565\n",
       "hackernews             2563\n",
       "iOSBeta                2424\n",
       "Windows10              2338\n",
       "linux4noobs            2275\n",
       "ProgrammerHumor        2194\n",
       "networking             2174\n",
       "androiddev             2026\n",
       "linux                  2013\n",
       "windows                2005\n",
       "javascript             1880\n",
       "learnprogramming       1813\n",
       "softwaregore           1746\n",
       "ios                    1737\n",
       "java                   1672\n",
       "androidthemes          1664\n",
       "chrome                 1548\n",
       "Python                 1474\n",
       "aws                    1471\n",
       "rust                   1466\n",
       "web_design             1361\n",
       "javahelp               1326\n",
       "arduino                1205\n",
       "iOSProgramming         1190\n",
       "mac                    1150\n",
       "csshelp                1101\n",
       "                       ... \n",
       "operabrowser            221\n",
       "mongodb                 197\n",
       "windowsinsiders         189\n",
       "macapps                 189\n",
       "LanguageTechnology      181\n",
       "softwaredevelopment     178\n",
       "djangolearning          173\n",
       "watchOSBeta             149\n",
       "browsers                142\n",
       "itsaunixsystem          138\n",
       "symfony                 124\n",
       "lua                     121\n",
       "nginx                   120\n",
       "windows8                119\n",
       "haskellquestions        117\n",
       "rubyonrails             117\n",
       "programmerreactions     117\n",
       "dartlang                103\n",
       "Meteor                  101\n",
       "redis                    86\n",
       "Julia                    82\n",
       "npm                      74\n",
       "erlang                   72\n",
       "zsh                      69\n",
       "OSXTweaks                67\n",
       "DatabaseHelp             59\n",
       "MaterialDesign           51\n",
       "d3js                     49\n",
       "cprogramming             48\n",
       "reviewmycode             44\n",
       "Name: subreddit, Length: 117, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99057, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98941, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = filtered_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192268</th>\n",
       "      <td>SQL Server Tuning advices</td>\n",
       "      <td>9</td>\n",
       "      <td>SQLServer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243232</th>\n",
       "      <td>Final solution to telephone number input problem</td>\n",
       "      <td>1195</td>\n",
       "      <td>ProgrammerHumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440672</th>\n",
       "      <td>Network config network generator</td>\n",
       "      <td>14</td>\n",
       "      <td>networking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346799</th>\n",
       "      <td>Nuances of Null – Using IsNull, Coalesce, Conc...</td>\n",
       "      <td>9</td>\n",
       "      <td>SQLServer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202502</th>\n",
       "      <td>A Visual Lexicon of LINQ - Simple Talk</td>\n",
       "      <td>13</td>\n",
       "      <td>dotnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470515</th>\n",
       "      <td>1 KB JavaScript library for building frontend ...</td>\n",
       "      <td>20</td>\n",
       "      <td>coolgithubprojects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258719</th>\n",
       "      <td>ScalaJSON first milestone release on scala-pla...</td>\n",
       "      <td>15</td>\n",
       "      <td>scala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546569</th>\n",
       "      <td>Thoughts on alternatives ORMs</td>\n",
       "      <td>16</td>\n",
       "      <td>csharp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392089</th>\n",
       "      <td>The TODOs app is the new “Hello World”</td>\n",
       "      <td>64</td>\n",
       "      <td>reactjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544313</th>\n",
       "      <td>US Condominium Average Monthly Rental Prices i...</td>\n",
       "      <td>6574</td>\n",
       "      <td>dataisbeautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425610</th>\n",
       "      <td>Flexbox-Froggy - This was submitted before by ...</td>\n",
       "      <td>28</td>\n",
       "      <td>css</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301896</th>\n",
       "      <td>[Question] What is this? 11.2 Beta. Never show...</td>\n",
       "      <td>13</td>\n",
       "      <td>iOSBeta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300879</th>\n",
       "      <td>Try React (from your browser) — React Armory</td>\n",
       "      <td>51</td>\n",
       "      <td>reactjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525402</th>\n",
       "      <td>Slowly Spinning Background help [/r/Spacefacts]</td>\n",
       "      <td>3</td>\n",
       "      <td>csshelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331046</th>\n",
       "      <td>Some lessons learned about using JaCoCo for ma...</td>\n",
       "      <td>10</td>\n",
       "      <td>java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569297</th>\n",
       "      <td>Elixir Package For Chocolatey NuGet updated to...</td>\n",
       "      <td>16</td>\n",
       "      <td>elixir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41875</th>\n",
       "      <td>Tool to customize touchpad behavior</td>\n",
       "      <td>10</td>\n",
       "      <td>windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9303</th>\n",
       "      <td>How do I make sure I perform well enough at an...</td>\n",
       "      <td>13</td>\n",
       "      <td>cscareerquestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236771</th>\n",
       "      <td>Chrome 59 to feature headless mode on all plat...</td>\n",
       "      <td>257</td>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474449</th>\n",
       "      <td>Any recommendations for creating nicer labels ...</td>\n",
       "      <td>7</td>\n",
       "      <td>iOSProgramming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  score  \\\n",
       "192268                          SQL Server Tuning advices      9   \n",
       "243232   Final solution to telephone number input problem   1195   \n",
       "440672                   Network config network generator     14   \n",
       "346799  Nuances of Null – Using IsNull, Coalesce, Conc...      9   \n",
       "202502             A Visual Lexicon of LINQ - Simple Talk     13   \n",
       "470515  1 KB JavaScript library for building frontend ...     20   \n",
       "258719  ScalaJSON first milestone release on scala-pla...     15   \n",
       "546569                      Thoughts on alternatives ORMs     16   \n",
       "392089             The TODOs app is the new “Hello World”     64   \n",
       "544313  US Condominium Average Monthly Rental Prices i...   6574   \n",
       "425610  Flexbox-Froggy - This was submitted before by ...     28   \n",
       "301896  [Question] What is this? 11.2 Beta. Never show...     13   \n",
       "300879       Try React (from your browser) — React Armory     51   \n",
       "525402    Slowly Spinning Background help [/r/Spacefacts]      3   \n",
       "331046  Some lessons learned about using JaCoCo for ma...     10   \n",
       "569297  Elixir Package For Chocolatey NuGet updated to...     16   \n",
       "41875                 Tool to customize touchpad behavior     10   \n",
       "9303    How do I make sure I perform well enough at an...     13   \n",
       "236771  Chrome 59 to feature headless mode on all plat...    257   \n",
       "474449  Any recommendations for creating nicer labels ...      7   \n",
       "\n",
       "                 subreddit  \n",
       "192268           SQLServer  \n",
       "243232     ProgrammerHumor  \n",
       "440672          networking  \n",
       "346799           SQLServer  \n",
       "202502              dotnet  \n",
       "470515  coolgithubprojects  \n",
       "258719               scala  \n",
       "546569              csharp  \n",
       "392089             reactjs  \n",
       "544313     dataisbeautiful  \n",
       "425610                 css  \n",
       "301896             iOSBeta  \n",
       "300879             reactjs  \n",
       "525402             csshelp  \n",
       "331046                java  \n",
       "569297              elixir  \n",
       "41875              windows  \n",
       "9303     cscareerquestions  \n",
       "236771          javascript  \n",
       "474449      iOSProgramming  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_data['title']\n",
    "y = filtered_data['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data into train (60%), val (20%), and test (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59364,)\n",
      "(19788,)\n",
      "(19789,)\n",
      "(59364,)\n",
      "(19788,)\n",
      "(19789,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=17)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=31)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Baseline\n",
    "Simple baseline using tf-idf based approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data['subreddit'])\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_val_vectors = vectorizer.transform(X_val)\n",
    "X_test_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def top_n_accuracy(y_true, probs, n=5):\n",
    "    top_n_list = []\n",
    "    for prob in probs:\n",
    "        top_n_list.append(np.argsort(-prob)[:n])\n",
    "    predictions = []\n",
    "    for prediction, top_n in zip(y_true, top_n_list):\n",
    "        predictions.append(int(prediction in top_n))\n",
    "    return np.sum(predictions) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = nb.predict(X_val_vectors)\n",
    "nb_probs = nb.predict_proba(X_val_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy:\n",
      " 0.288392541311\n",
      "Top 5 accuracy:\n",
      " 0.592298751832\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.17      0.99      0.28      1362\n",
      "          1       0.73      0.32      0.44       180\n",
      "          2       0.00      0.00      0.00       105\n",
      "          3       0.56      0.02      0.04       216\n",
      "          4       1.00      0.02      0.03       125\n",
      "          5       0.00      0.00      0.00        91\n",
      "          6       1.00      0.10      0.18       101\n",
      "          7       0.00      0.00      0.00        69\n",
      "          8       0.00      0.00      0.00        18\n",
      "          9       1.00      0.01      0.02        89\n",
      "         10       0.00      0.00      0.00        18\n",
      "         11       0.00      0.00      0.00        38\n",
      "         12       0.00      0.00      0.00       115\n",
      "         13       0.00      0.00      0.00        13\n",
      "         14       0.00      0.00      0.00        19\n",
      "         15       0.00      0.00      0.00        20\n",
      "         16       0.00      0.00      0.00        52\n",
      "         17       0.41      0.09      0.15       391\n",
      "         18       0.52      0.04      0.07       307\n",
      "         19       0.50      0.01      0.02        88\n",
      "         20       0.00      0.00      0.00        49\n",
      "         21       0.00      0.00      0.00        47\n",
      "         22       0.52      0.40      0.45       486\n",
      "         23       0.69      0.23      0.34       393\n",
      "         24       0.95      0.38      0.54       327\n",
      "         25       1.00      0.02      0.05        82\n",
      "         26       0.93      0.28      0.43       252\n",
      "         27       0.87      0.14      0.24       184\n",
      "         28       0.81      0.44      0.57       309\n",
      "         29       0.00      0.00      0.00        59\n",
      "         30       0.00      0.00      0.00        33\n",
      "         31       0.66      0.32      0.44       305\n",
      "         32       0.00      0.00      0.00        62\n",
      "         33       0.00      0.00      0.00       102\n",
      "         34       0.00      0.00      0.00        64\n",
      "         35       0.00      0.00      0.00        95\n",
      "         36       0.00      0.00      0.00        62\n",
      "         37       1.00      0.01      0.01       151\n",
      "         38       0.00      0.00      0.00        57\n",
      "         39       0.00      0.00      0.00        95\n",
      "         40       1.00      0.05      0.09       181\n",
      "         41       0.00      0.00      0.00         8\n",
      "         42       0.00      0.00      0.00        89\n",
      "         43       0.30      0.88      0.45       747\n",
      "         44       0.50      0.01      0.02       166\n",
      "         45       1.00      0.01      0.02       107\n",
      "         46       0.92      0.48      0.63       227\n",
      "         47       0.00      0.00      0.00         9\n",
      "         48       0.00      0.00      0.00        14\n",
      "         49       0.96      0.29      0.45       167\n",
      "         50       0.65      0.11      0.19       219\n",
      "         51       0.00      0.00      0.00        90\n",
      "         52       1.00      0.04      0.08       118\n",
      "         53       0.00      0.00      0.00        26\n",
      "         54       0.94      0.14      0.24       115\n",
      "         55       0.67      0.28      0.39       161\n",
      "         56       1.00      0.02      0.04        51\n",
      "         57       0.00      0.00      0.00        72\n",
      "         58       0.00      0.00      0.00        11\n",
      "         59       1.00      0.02      0.04        49\n",
      "         60       0.00      0.00      0.00        59\n",
      "         61       0.00      0.00      0.00        42\n",
      "         62       0.83      0.05      0.09       209\n",
      "         63       0.45      0.12      0.19       542\n",
      "         64       0.91      0.22      0.36       224\n",
      "         65       0.00      0.00      0.00        28\n",
      "         66       0.00      0.00      0.00        67\n",
      "         67       0.65      0.71      0.68       500\n",
      "         68       0.45      0.08      0.14       255\n",
      "         69       0.58      0.02      0.04       331\n",
      "         70       0.00      0.00      0.00        36\n",
      "         71       0.65      0.38      0.48       335\n",
      "         72       0.41      0.05      0.09       267\n",
      "         73       0.32      0.26      0.29       374\n",
      "         74       0.00      0.00      0.00        51\n",
      "         75       1.00      0.02      0.03       124\n",
      "         76       0.00      0.00      0.00       102\n",
      "         77       0.25      0.07      0.11       396\n",
      "         78       0.21      0.72      0.33       605\n",
      "         79       0.57      0.13      0.21       397\n",
      "         80       0.30      0.01      0.03       420\n",
      "         81       0.00      0.00      0.00        69\n",
      "         82       0.23      0.77      0.35       734\n",
      "         83       0.00      0.00      0.00        24\n",
      "         84       0.71      0.14      0.23       213\n",
      "         85       0.00      0.00      0.00        38\n",
      "         86       0.00      0.00      0.00        38\n",
      "         87       0.00      0.00      0.00        52\n",
      "         88       0.84      0.43      0.57       412\n",
      "         89       0.00      0.00      0.00        27\n",
      "         90       0.81      0.14      0.24       183\n",
      "         91       0.00      0.00      0.00        20\n",
      "         92       0.00      0.00      0.00       114\n",
      "         93       0.00      0.00      0.00        31\n",
      "         94       0.00      0.00      0.00        87\n",
      "         95       0.71      0.07      0.12        74\n",
      "         96       0.00      0.00      0.00        21\n",
      "         97       0.75      0.02      0.04       149\n",
      "         98       0.84      0.31      0.45       227\n",
      "         99       0.67      0.24      0.35       226\n",
      "        100       0.00      0.00      0.00        14\n",
      "        101       0.00      0.00      0.00        12\n",
      "        102       0.56      0.07      0.13       140\n",
      "        103       0.00      0.00      0.00        16\n",
      "        104       0.86      0.46      0.60       295\n",
      "        105       1.00      0.03      0.07        89\n",
      "        106       0.00      0.00      0.00        30\n",
      "        107       0.58      0.04      0.08       313\n",
      "        108       0.80      0.06      0.11       136\n",
      "        109       0.00      0.00      0.00        19\n",
      "        110       0.00      0.00      0.00        23\n",
      "        111       0.23      0.01      0.02       269\n",
      "        112       0.16      0.28      0.20       551\n",
      "        113       0.57      0.11      0.19       444\n",
      "        114       0.00      0.00      0.00        28\n",
      "        115       0.00      0.00      0.00        33\n",
      "        116       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.48      0.29      0.24     19789\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victorkwak/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Top 1 accuracy:\\n', top_n_accuracy(y_val, nb_probs, 1))\n",
    "print('Top 5 accuracy:\\n', top_n_accuracy(y_val, nb_probs, 5))\n",
    "print(classification_report(y_val, nb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC(penalty='l2', loss='squared_hinge', multi_class='ovr', max_iter=1000)\n",
    "svm.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.501288594674\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.87      0.80      1362\n",
      "          1       0.64      0.69      0.67       180\n",
      "          2       0.18      0.10      0.13       105\n",
      "          3       0.36      0.31      0.33       216\n",
      "          4       0.47      0.50      0.48       125\n",
      "          5       0.19      0.15      0.17        91\n",
      "          6       0.81      0.70      0.75       101\n",
      "          7       0.25      0.20      0.22        69\n",
      "          8       0.50      0.06      0.10        18\n",
      "          9       0.65      0.62      0.64        89\n",
      "         10       0.88      0.78      0.82        18\n",
      "         11       0.45      0.37      0.41        38\n",
      "         12       0.61      0.46      0.52       115\n",
      "         13       0.60      0.23      0.33        13\n",
      "         14       0.88      0.74      0.80        19\n",
      "         15       0.33      0.05      0.09        20\n",
      "         16       0.65      0.60      0.62        52\n",
      "         17       0.23      0.30      0.26       391\n",
      "         18       0.40      0.30      0.34       307\n",
      "         19       0.60      0.57      0.58        88\n",
      "         20       0.35      0.37      0.36        49\n",
      "         21       0.06      0.02      0.03        47\n",
      "         22       0.47      0.54      0.50       486\n",
      "         23       0.58      0.54      0.56       393\n",
      "         24       0.65      0.61      0.63       327\n",
      "         25       0.37      0.32      0.34        82\n",
      "         26       0.70      0.64      0.67       252\n",
      "         27       0.65      0.68      0.67       184\n",
      "         28       0.75      0.78      0.77       309\n",
      "         29       0.24      0.20      0.22        59\n",
      "         30       0.30      0.21      0.25        33\n",
      "         31       0.55      0.72      0.62       305\n",
      "         32       0.36      0.15      0.21        62\n",
      "         33       0.04      0.02      0.03       102\n",
      "         34       0.21      0.14      0.17        64\n",
      "         35       0.14      0.08      0.10        95\n",
      "         36       0.59      0.37      0.46        62\n",
      "         37       0.21      0.19      0.20       151\n",
      "         38       0.44      0.32      0.37        57\n",
      "         39       0.10      0.06      0.08        95\n",
      "         40       0.58      0.46      0.51       181\n",
      "         41       0.00      0.00      0.00         8\n",
      "         42       0.55      0.48      0.51        89\n",
      "         43       0.51      0.69      0.59       747\n",
      "         44       0.21      0.16      0.18       166\n",
      "         45       0.35      0.42      0.38       107\n",
      "         46       0.69      0.82      0.75       227\n",
      "         47       0.50      0.44      0.47         9\n",
      "         48       0.90      0.64      0.75        14\n",
      "         49       0.83      0.81      0.82       167\n",
      "         50       0.51      0.52      0.51       219\n",
      "         51       0.54      0.49      0.51        90\n",
      "         52       0.68      0.68      0.68       118\n",
      "         53       0.00      0.00      0.00        26\n",
      "         54       0.71      0.64      0.68       115\n",
      "         55       0.49      0.49      0.49       161\n",
      "         56       0.91      0.78      0.84        51\n",
      "         57       0.57      0.39      0.46        72\n",
      "         58       0.69      0.82      0.75        11\n",
      "         59       0.59      0.69      0.64        49\n",
      "         60       0.48      0.58      0.52        59\n",
      "         61       0.23      0.26      0.25        42\n",
      "         62       0.44      0.36      0.40       209\n",
      "         63       0.34      0.31      0.33       542\n",
      "         64       0.70      0.65      0.67       224\n",
      "         65       0.17      0.04      0.06        28\n",
      "         66       0.29      0.25      0.27        67\n",
      "         67       0.76      0.93      0.84       500\n",
      "         68       0.43      0.38      0.41       255\n",
      "         69       0.47      0.52      0.49       331\n",
      "         70       0.62      0.14      0.23        36\n",
      "         71       0.57      0.65      0.61       335\n",
      "         72       0.28      0.30      0.29       267\n",
      "         73       0.36      0.38      0.37       374\n",
      "         74       0.44      0.35      0.39        51\n",
      "         75       0.84      0.65      0.73       124\n",
      "         76       0.19      0.13      0.15       102\n",
      "         77       0.24      0.19      0.21       396\n",
      "         78       0.38      0.53      0.44       605\n",
      "         79       0.45      0.45      0.45       397\n",
      "         80       0.23      0.20      0.21       420\n",
      "         81       0.18      0.09      0.12        69\n",
      "         82       0.39      0.45      0.42       734\n",
      "         83       0.90      0.75      0.82        24\n",
      "         84       0.50      0.59      0.54       213\n",
      "         85       0.26      0.13      0.18        38\n",
      "         86       0.73      0.58      0.65        38\n",
      "         87       0.45      0.42      0.44        52\n",
      "         88       0.64      0.69      0.66       412\n",
      "         89       0.44      0.44      0.44        27\n",
      "         90       0.49      0.55      0.52       183\n",
      "         91       0.25      0.05      0.08        20\n",
      "         92       0.25      0.18      0.21       114\n",
      "         93       0.75      0.58      0.65        31\n",
      "         94       0.26      0.17      0.21        87\n",
      "         95       0.69      0.61      0.65        74\n",
      "         96       0.83      0.48      0.61        21\n",
      "         97       0.52      0.45      0.48       149\n",
      "         98       0.71      0.69      0.70       227\n",
      "         99       0.65      0.72      0.68       226\n",
      "        100       0.73      0.57      0.64        14\n",
      "        101       0.00      0.00      0.00        12\n",
      "        102       0.68      0.56      0.62       140\n",
      "        103       0.00      0.00      0.00        16\n",
      "        104       0.76      0.78      0.77       295\n",
      "        105       0.83      0.71      0.76        89\n",
      "        106       0.12      0.10      0.11        30\n",
      "        107       0.29      0.33      0.31       313\n",
      "        108       0.51      0.45      0.48       136\n",
      "        109       0.90      1.00      0.95        19\n",
      "        110       0.80      0.52      0.63        23\n",
      "        111       0.28      0.28      0.28       269\n",
      "        112       0.24      0.18      0.21       551\n",
      "        113       0.42      0.41      0.41       444\n",
      "        114       0.67      0.14      0.24        28\n",
      "        115       0.36      0.30      0.33        33\n",
      "        116       0.78      0.44      0.56        16\n",
      "\n",
      "avg / total       0.49      0.50      0.49     19789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_predictions = svm.predict(X_val_vectors)\n",
    "\n",
    "print(accuracy_score(y_val, svm_predictions))\n",
    "print(classification_report(y_val, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "\n",
    "tagged_documents = []\n",
    "tokens = None\n",
    "for text, label in zip(X_train, y_train):\n",
    "    text = text.lower()\n",
    "    tokens = utils.simple_preprocess(text)\n",
    "    tagged_documents.append(TaggedDocument(tokens, [label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['lessons', 'learned', 'from', 'my', 'latest', 'game', 'iteration', 'from', 'stars', 'to', 'over'], tags=[71]),\n",
       " TaggedDocument(words=['little', 'asp', 'net', 'core', 'book'], tags=[112]),\n",
       " TaggedDocument(words=['responsive', 'background', 'images', 'with', 'javascript'], tags=[111]),\n",
       " TaggedDocument(words=['can', 'ssh', 'to', 'virtual', 'machine', 'when', 'ipv', 'is', 'set', 'to', 'automatic', 'dhcp', 'but', 'can', 'ssh', 'when', 'use', 'manual', 'and', 'input', 'my', 'own', 'addresses'], tags=[82]),\n",
       " TaggedDocument(words=['conversational', 'dataset'], tags=[51])]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(size=64, window=7, min_count=1, workers=4, iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10406315"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build_vocab(tagged_documents)\n",
    "model.train(tagged_documents, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors = X_train.map(lambda title: model.infer_vector(utils.simple_preprocess(title))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors = np.array(list(X_train_vectors), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59364, 64)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC(penalty='l2', loss='squared_hinge', multi_class='ovr', max_iter=1000)\n",
    "svm.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_vectors = X_val.map(lambda title: model.infer_vector(utils.simple_preprocess(title))).values\n",
    "X_val_vectors = np.array(list(X_val_vectors), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predictions = svm.predict(X_val_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.294557582495\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.67      0.44      1362\n",
      "          1       0.50      0.73      0.59       180\n",
      "          2       0.00      0.00      0.00       105\n",
      "          3       0.29      0.07      0.12       216\n",
      "          4       0.67      0.03      0.06       125\n",
      "          5       0.00      0.00      0.00        91\n",
      "          6       0.54      0.50      0.52       101\n",
      "          7       0.00      0.00      0.00        69\n",
      "          8       0.00      0.00      0.00        18\n",
      "          9       0.35      0.30      0.33        89\n",
      "         10       0.67      0.11      0.19        18\n",
      "         11       0.00      0.00      0.00        38\n",
      "         12       0.45      0.09      0.15       115\n",
      "         13       0.00      0.00      0.00        13\n",
      "         14       0.00      0.00      0.00        19\n",
      "         15       0.00      0.00      0.00        20\n",
      "         16       0.50      0.02      0.04        52\n",
      "         17       0.10      0.07      0.08       391\n",
      "         18       0.33      0.33      0.33       307\n",
      "         19       0.38      0.03      0.06        88\n",
      "         20       0.00      0.00      0.00        49\n",
      "         21       0.00      0.00      0.00        47\n",
      "         22       0.23      0.30      0.26       486\n",
      "         23       0.23      0.33      0.27       393\n",
      "         24       0.29      0.53      0.38       327\n",
      "         25       0.14      0.01      0.02        82\n",
      "         26       0.36      0.57      0.44       252\n",
      "         27       0.33      0.44      0.38       184\n",
      "         28       0.33      0.58      0.42       309\n",
      "         29       0.00      0.00      0.00        59\n",
      "         30       0.00      0.00      0.00        33\n",
      "         31       0.28      0.40      0.33       305\n",
      "         32       0.00      0.00      0.00        62\n",
      "         33       0.00      0.00      0.00       102\n",
      "         34       0.00      0.00      0.00        64\n",
      "         35       0.00      0.00      0.00        95\n",
      "         36       0.00      0.00      0.00        62\n",
      "         37       0.00      0.00      0.00       151\n",
      "         38       0.00      0.00      0.00        57\n",
      "         39       0.00      0.00      0.00        95\n",
      "         40       0.38      0.16      0.22       181\n",
      "         41       0.00      0.00      0.00         8\n",
      "         42       0.30      0.07      0.11        89\n",
      "         43       0.22      0.39      0.29       747\n",
      "         44       0.00      0.00      0.00       166\n",
      "         45       0.36      0.18      0.24       107\n",
      "         46       0.36      0.63      0.46       227\n",
      "         47       0.00      0.00      0.00         9\n",
      "         48       0.00      0.00      0.00        14\n",
      "         49       0.44      0.69      0.54       167\n",
      "         50       0.22      0.04      0.06       219\n",
      "         51       0.35      0.19      0.25        90\n",
      "         52       0.56      0.58      0.57       118\n",
      "         53       0.00      0.00      0.00        26\n",
      "         54       0.39      0.36      0.37       115\n",
      "         55       0.41      0.19      0.26       161\n",
      "         56       0.73      0.31      0.44        51\n",
      "         57       0.00      0.00      0.00        72\n",
      "         58       0.00      0.00      0.00        11\n",
      "         59       0.53      0.33      0.41        49\n",
      "         60       0.35      0.46      0.39        59\n",
      "         61       0.00      0.00      0.00        42\n",
      "         62       0.36      0.63      0.46       209\n",
      "         63       0.17      0.21      0.19       542\n",
      "         64       0.40      0.52      0.45       224\n",
      "         65       0.00      0.00      0.00        28\n",
      "         66       0.00      0.00      0.00        67\n",
      "         67       0.33      0.64      0.44       500\n",
      "         68       0.25      0.08      0.12       255\n",
      "         69       0.29      0.28      0.29       331\n",
      "         70       0.00      0.00      0.00        36\n",
      "         71       0.27      0.49      0.35       335\n",
      "         72       0.19      0.04      0.06       267\n",
      "         73       0.22      0.24      0.23       374\n",
      "         74       0.00      0.00      0.00        51\n",
      "         75       0.55      0.57      0.56       124\n",
      "         76       0.00      0.00      0.00       102\n",
      "         77       0.00      0.00      0.00       396\n",
      "         78       0.16      0.25      0.20       605\n",
      "         79       0.25      0.27      0.26       397\n",
      "         80       0.07      0.01      0.02       420\n",
      "         81       0.00      0.00      0.00        69\n",
      "         82       0.20      0.34      0.25       734\n",
      "         83       0.69      0.38      0.49        24\n",
      "         84       0.30      0.39      0.34       213\n",
      "         85       0.00      0.00      0.00        38\n",
      "         86       0.50      0.26      0.34        38\n",
      "         87       1.00      0.02      0.04        52\n",
      "         88       0.30      0.59      0.40       412\n",
      "         89       0.00      0.00      0.00        27\n",
      "         90       0.33      0.07      0.12       183\n",
      "         91       0.00      0.00      0.00        20\n",
      "         92       0.00      0.00      0.00       114\n",
      "         93       1.00      0.03      0.06        31\n",
      "         94       0.00      0.00      0.00        87\n",
      "         95       0.47      0.51      0.49        74\n",
      "         96       0.00      0.00      0.00        21\n",
      "         97       0.49      0.28      0.36       149\n",
      "         98       0.31      0.23      0.26       227\n",
      "         99       0.45      0.59      0.51       226\n",
      "        100       0.00      0.00      0.00        14\n",
      "        101       0.00      0.00      0.00        12\n",
      "        102       0.45      0.49      0.47       140\n",
      "        103       0.00      0.00      0.00        16\n",
      "        104       0.43      0.71      0.53       295\n",
      "        105       0.55      0.42      0.47        89\n",
      "        106       0.00      0.00      0.00        30\n",
      "        107       0.14      0.03      0.04       313\n",
      "        108       0.37      0.38      0.37       136\n",
      "        109       1.00      0.05      0.10        19\n",
      "        110       1.00      0.04      0.08        23\n",
      "        111       0.17      0.06      0.08       269\n",
      "        112       0.10      0.03      0.05       551\n",
      "        113       0.27      0.14      0.18       444\n",
      "        114       0.00      0.00      0.00        28\n",
      "        115       0.00      0.00      0.00        33\n",
      "        116       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.25      0.29      0.24     19789\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victorkwak/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_val, svm_predictions))\n",
    "print(classification_report(y_val, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH_STOP_WORDS = frozenset([\n",
    "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
    "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
    "    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
    "    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
    "    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
    "    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
    "    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
    "    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\",\n",
    "    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
    "    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
    "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
    "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
    "    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
    "    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
    "    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
    "    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
    "    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
    "    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
    "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
    "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
    "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
    "    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
    "    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
    "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
    "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
    "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
    "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "\"yourselves\"])\n",
    "\n",
    "\n",
    "def format_for_fastext(X, y, filename):\n",
    "    prefix = '__label__'\n",
    "    f = open(''.join(['data/', filename]), 'w')\n",
    "    for title, label in zip(X, y):\n",
    "        title = title.lower()\n",
    "        tokens = utils.simple_preprocess(title)\n",
    "        tokens = [token for token in tokens if token not in ENGLISH_STOP_WORDS]\n",
    "        f.write(''.join([prefix, str(label), ' ', ' '.join(tokens), '\\n']))\n",
    "    f.close()\n",
    "    \n",
    "format_for_fastext(X_train, y_train, 'reddit_fasttext_train.txt')\n",
    "format_for_fastext(X_val, y_val, 'reddit_fasttext_val.txt')\n",
    "format_for_fastext(X_test, y_test, 'reddit_fasttext_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__24', '__label__17', '__label__107', '__label__68', '__label__63'),\n",
       " array([ 0.12639114,  0.06488035,  0.05542552,  0.03495135,  0.03151938]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(X_val.iloc[2], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fasttext(y, X, classifier, n = 1):\n",
    "    match = []\n",
    "    for true, string in zip(y, X):\n",
    "        predictions = list(classifier.predict(string, n)[0])\n",
    "        for i in range(n):\n",
    "            predictions[i] = int(predictions[i].split('__label__')[1])\n",
    "        match.append(int(true in predictions))\n",
    "    return np.array(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-6816f4a9bc91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                 )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_fasttext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-91-1657f41622ae>\u001b[0m in \u001b[0;36mtest_fasttext\u001b[0;34m(y, X, classifier)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__label__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'list'"
     ]
    }
   ],
   "source": [
    "import fastText as fasttext\n",
    "\n",
    "classifier = fasttext.train_supervised(input='data/reddit_fasttext_train.txt',\n",
    "                                 lr=0.1,\n",
    "                                 epoch=30,\n",
    "                                 dim=84,\n",
    "                                 minn=2,\n",
    "                                 maxn=5\n",
    "                                )\n",
    "\n",
    "correct = test_fasttext(y_val, X_val, classifier)\n",
    "correct.sum() / y_val.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.save_model('models/fasttext.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastText import load_model\n",
    "\n",
    "classifier = load_model('models/fasttext.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72782859164182123"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = test_fasttext(y_val, X_val, classifier, 10)\n",
    "correct.sum() / y_val.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
