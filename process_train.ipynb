{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/cs_subs.csv')  # unzip this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['subreddit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624289, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Android                61202\n",
       "learnprogramming       35288\n",
       "cscareerquestions      32935\n",
       "Windows10              27726\n",
       "webdev                 26849\n",
       "dataisbeautiful        24389\n",
       "softwaregore           23746\n",
       "web_design             22159\n",
       "ProgrammerHumor        19208\n",
       "learnpython            17634\n",
       "raspberry_pi           15659\n",
       "iOSBeta                14508\n",
       "linux                  14058\n",
       "javascript             12971\n",
       "linuxquestions         11464\n",
       "hackernews             11134\n",
       "Python                 11119\n",
       "windows                10132\n",
       "androiddev             10130\n",
       "mac                     9841\n",
       "ios                     9754\n",
       "arduino                 9603\n",
       "java                    9401\n",
       "networking              9378\n",
       "linux4noobs             8004\n",
       "androidthemes           7895\n",
       "chrome                  5862\n",
       "iOSProgramming          5647\n",
       "rust                    5489\n",
       "datascience             5374\n",
       "                       ...  \n",
       "redis                    241\n",
       "dartlang                 240\n",
       "programmerreactions      237\n",
       "Julia                    217\n",
       "reviewmycode             216\n",
       "zsh                      210\n",
       "OSXTweaks                198\n",
       "erlang                   186\n",
       "d3js                     179\n",
       "MaterialDesign           179\n",
       "npm                      164\n",
       "c_language               143\n",
       "learnphp                 120\n",
       "Heroku                   118\n",
       "dailyprogrammer          114\n",
       "cakephp                  113\n",
       "learnruby                106\n",
       "mariadb                   95\n",
       "tinycode                  93\n",
       "groovy                    90\n",
       "pythoncoding              88\n",
       "vagrant                   77\n",
       "Cprog                     38\n",
       "androiddesign             36\n",
       "osxterminal               31\n",
       "learnlaravel              28\n",
       "shell                     24\n",
       "haskelltil                24\n",
       "AskCompSci                17\n",
       "dotfiles                  17\n",
       "Name: subreddit, Length: 136, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119376</th>\n",
       "      <td>What phone should I get?</td>\n",
       "      <td>1</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378136</th>\n",
       "      <td>NATIVE sounds</td>\n",
       "      <td>0</td>\n",
       "      <td>raspberry_pi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542046</th>\n",
       "      <td>African Americans as percentage of local popul...</td>\n",
       "      <td>8</td>\n",
       "      <td>dataisbeautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43311</th>\n",
       "      <td>How does a succesful data science team look like?</td>\n",
       "      <td>0</td>\n",
       "      <td>datascience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332620</th>\n",
       "      <td>Wall Street Furious Over BitCoin Millionaires</td>\n",
       "      <td>1</td>\n",
       "      <td>dataisbeautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7243</th>\n",
       "      <td>Must it or mustn't it?!</td>\n",
       "      <td>6</td>\n",
       "      <td>softwaregore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466066</th>\n",
       "      <td>2016 American Community Survey (ACS) Data Map</td>\n",
       "      <td>1</td>\n",
       "      <td>dataisbeautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213322</th>\n",
       "      <td>[Co-ops &amp;amp; Internships] Help? I chose a Uni...</td>\n",
       "      <td>0</td>\n",
       "      <td>cscareerquestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324399</th>\n",
       "      <td>Google is now offering a Mobile Sites certific...</td>\n",
       "      <td>1</td>\n",
       "      <td>Web_Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368673</th>\n",
       "      <td>DevOps: How to Give Your Business Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  score  \\\n",
       "119376                           What phone should I get?      1   \n",
       "378136                                      NATIVE sounds      0   \n",
       "542046  African Americans as percentage of local popul...      8   \n",
       "43311   How does a succesful data science team look like?      0   \n",
       "332620      Wall Street Furious Over BitCoin Millionaires      1   \n",
       "7243                              Must it or mustn't it?!      6   \n",
       "466066      2016 American Community Survey (ACS) Data Map      1   \n",
       "213322  [Co-ops &amp; Internships] Help? I chose a Uni...      0   \n",
       "324399  Google is now offering a Mobile Sites certific...      1   \n",
       "368673         DevOps: How to Give Your Business Velocity      1   \n",
       "\n",
       "                subreddit  \n",
       "119376            Android  \n",
       "378136       raspberry_pi  \n",
       "542046    dataisbeautiful  \n",
       "43311         datascience  \n",
       "332620    dataisbeautiful  \n",
       "7243         softwaregore  \n",
       "466066    dataisbeautiful  \n",
       "213322  cscareerquestions  \n",
       "324399    Web_Development  \n",
       "368673               node  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are filtering non-latin workds, and also subreddits that have less than 800 posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data['subreddit'].value_counts()\n",
    "counts = counts[counts > 800]\n",
    "top_values = list(counts.index)\n",
    "data = data[~data['subreddit'].isin(top_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata as ud\n",
    "\n",
    "latin_letters = {}\n",
    "\n",
    "\n",
    "def is_latin(uchr):\n",
    "    try:\n",
    "        return latin_letters[uchr]\n",
    "    except KeyError:\n",
    "        return latin_letters.setdefault(uchr, 'LATIN' in ud.name(uchr))\n",
    "\n",
    "\n",
    "def only_roman_chars(unistr):\n",
    "    return all(is_latin(uchr)\n",
    "               for uchr in unistr\n",
    "               if uchr.isalpha())  # isalpha suggested by John Machin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_latin'] = data['subreddit'].apply(only_roman_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['is_latin'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14019, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13949, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13949, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>is_latin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99131</th>\n",
       "      <td>Look who’s here! Long time no see!</td>\n",
       "      <td>0</td>\n",
       "      <td>nginx</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243348</th>\n",
       "      <td>How to search good places to travel (mongoimpo...</td>\n",
       "      <td>1</td>\n",
       "      <td>mongodb</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157617</th>\n",
       "      <td>Looking for contributors for ruby gem project,...</td>\n",
       "      <td>6</td>\n",
       "      <td>rubyonrails</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588946</th>\n",
       "      <td>How advanced are plagiarism detection algorith...</td>\n",
       "      <td>5</td>\n",
       "      <td>LanguageTechnology</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46747</th>\n",
       "      <td>Free аnd well trustеd Intеrnеt dаting websitе ...</td>\n",
       "      <td>0</td>\n",
       "      <td>learnruby</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75880</th>\n",
       "      <td>A Rubyist's Guide to Postgresql's Explain</td>\n",
       "      <td>1</td>\n",
       "      <td>PostgreSQL</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5407</th>\n",
       "      <td>Surface Book and build 15019 problems</td>\n",
       "      <td>5</td>\n",
       "      <td>windowsinsiders</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522027</th>\n",
       "      <td>Building a Database from Scratch - Benoit Ches...</td>\n",
       "      <td>11</td>\n",
       "      <td>erlang</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149451</th>\n",
       "      <td>How to Remove Topgamesnetwork.com Totally?</td>\n",
       "      <td>1</td>\n",
       "      <td>browsers</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351150</th>\n",
       "      <td>Code for \"Labeling the Semantic Roles of Comma...</td>\n",
       "      <td>4</td>\n",
       "      <td>LanguageTechnology</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500904</th>\n",
       "      <td>Database options for web application</td>\n",
       "      <td>2</td>\n",
       "      <td>DatabaseHelp</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606730</th>\n",
       "      <td>Q: change cursor shape based on user id</td>\n",
       "      <td>3</td>\n",
       "      <td>zsh</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176483</th>\n",
       "      <td>How can I create a find() query that matches a...</td>\n",
       "      <td>1</td>\n",
       "      <td>mongodb</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513468</th>\n",
       "      <td>I'm back. This time I would like some advice o...</td>\n",
       "      <td>33</td>\n",
       "      <td>MaterialDesign</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566098</th>\n",
       "      <td>Valid input being marked as invalid after subm...</td>\n",
       "      <td>2</td>\n",
       "      <td>jquery</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548186</th>\n",
       "      <td>What Do You Mean By PostgreSQL?</td>\n",
       "      <td>1</td>\n",
       "      <td>PostgreSQL</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583637</th>\n",
       "      <td>FemtoCleaner – The code behind femtocleaner</td>\n",
       "      <td>1</td>\n",
       "      <td>Julia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31099</th>\n",
       "      <td>Sex dating website. Free, huge and good choice...</td>\n",
       "      <td>0</td>\n",
       "      <td>operabrowser</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213650</th>\n",
       "      <td>Storing phone numbers in PostgreSQL with libph...</td>\n",
       "      <td>9</td>\n",
       "      <td>PostgreSQL</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553483</th>\n",
       "      <td>CakePHP 3.5.0-RC1 Released</td>\n",
       "      <td>4</td>\n",
       "      <td>cakephp</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  score  \\\n",
       "99131                  Look who’s here! Long time no see!      0   \n",
       "243348  How to search good places to travel (mongoimpo...      1   \n",
       "157617  Looking for contributors for ruby gem project,...      6   \n",
       "588946  How advanced are plagiarism detection algorith...      5   \n",
       "46747   Free аnd well trustеd Intеrnеt dаting websitе ...      0   \n",
       "75880           A Rubyist's Guide to Postgresql's Explain      1   \n",
       "5407                Surface Book and build 15019 problems      5   \n",
       "522027  Building a Database from Scratch - Benoit Ches...     11   \n",
       "149451         How to Remove Topgamesnetwork.com Totally?      1   \n",
       "351150  Code for \"Labeling the Semantic Roles of Comma...      4   \n",
       "500904               Database options for web application      2   \n",
       "606730            Q: change cursor shape based on user id      3   \n",
       "176483  How can I create a find() query that matches a...      1   \n",
       "513468  I'm back. This time I would like some advice o...     33   \n",
       "566098  Valid input being marked as invalid after subm...      2   \n",
       "548186                    What Do You Mean By PostgreSQL?      1   \n",
       "583637        FemtoCleaner – The code behind femtocleaner      1   \n",
       "31099   Sex dating website. Free, huge and good choice...      0   \n",
       "213650  Storing phone numbers in PostgreSQL with libph...      9   \n",
       "553483                         CakePHP 3.5.0-RC1 Released      4   \n",
       "\n",
       "                 subreddit  is_latin  \n",
       "99131                nginx      True  \n",
       "243348             mongodb      True  \n",
       "157617         rubyonrails      True  \n",
       "588946  LanguageTechnology      True  \n",
       "46747            learnruby      True  \n",
       "75880           PostgreSQL      True  \n",
       "5407       windowsinsiders      True  \n",
       "522027              erlang      True  \n",
       "149451            browsers      True  \n",
       "351150  LanguageTechnology      True  \n",
       "500904        DatabaseHelp      True  \n",
       "606730                 zsh      True  \n",
       "176483             mongodb      True  \n",
       "513468      MaterialDesign      True  \n",
       "566098              jquery      True  \n",
       "548186          PostgreSQL      True  \n",
       "583637               Julia      True  \n",
       "31099         operabrowser      True  \n",
       "213650          PostgreSQL      True  \n",
       "553483             cakephp      True  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['title']\n",
    "y = data['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data into train (60%), val (20%), and test (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8369,)\n",
      "(2790,)\n",
      "(2790,)\n",
      "(8369,)\n",
      "(2790,)\n",
      "(2790,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=17)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=31)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Baseline\n",
    "Simple baseline using tf-idf based approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data['subreddit'])\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_val_vectors = vectorizer.transform(X_val)\n",
    "X_test_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def top_n_accuracy(y_true, probs, n=5):\n",
    "    top_n_list = []\n",
    "    for prob in probs:\n",
    "        top_n_list.append(np.argsort(-prob)[:n])\n",
    "    predictions = []\n",
    "    for prediction, top_n in zip(y_true, top_n_list):\n",
    "        predictions.append(int(prediction in top_n))\n",
    "    return np.sum(predictions) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = nb.predict(X_val_vectors)\n",
    "nb_probs = nb.predict_proba(X_val_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy:\n",
      " 0.505734767025\n",
      "Top 5 accuracy:\n",
      " 0.688888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         5\n",
      "          1       0.00      0.00      0.00         7\n",
      "          2       0.69      0.16      0.26        55\n",
      "          3       0.00      0.00      0.00        27\n",
      "          4       1.00      0.18      0.31        50\n",
      "          5       0.70      0.63      0.67        98\n",
      "          6       0.80      0.18      0.30        44\n",
      "          7       0.95      0.32      0.48        59\n",
      "          8       0.00      0.00      0.00        36\n",
      "          9       0.34      0.81      0.48       155\n",
      "         10       0.00      0.00      0.00         6\n",
      "         11       0.64      0.75      0.69       122\n",
      "         12       0.00      0.00      0.00        28\n",
      "         13       1.00      0.39      0.56        18\n",
      "         14       0.26      0.87      0.40       145\n",
      "         15       0.83      0.65      0.73        77\n",
      "         16       1.00      0.06      0.12        47\n",
      "         17       0.95      0.90      0.92        20\n",
      "         18       1.00      0.45      0.62        47\n",
      "         19       0.72      0.44      0.55        86\n",
      "         20       0.00      0.00      0.00         2\n",
      "         21       0.89      0.21      0.33        39\n",
      "         22       0.00      0.00      0.00        23\n",
      "         23       0.86      0.28      0.42        87\n",
      "         24       0.00      0.00      0.00         4\n",
      "         25       0.79      0.40      0.53        77\n",
      "         26       0.29      0.81      0.43       124\n",
      "         27       0.00      0.00      0.00         2\n",
      "         28       0.00      0.00      0.00        17\n",
      "         29       0.00      0.00      0.00        17\n",
      "         30       0.96      0.32      0.47        73\n",
      "         31       0.67      0.63      0.65       117\n",
      "         32       1.00      0.15      0.26        20\n",
      "         33       0.63      0.62      0.62       104\n",
      "         34       0.72      0.83      0.77        69\n",
      "         35       0.00      0.00      0.00        27\n",
      "         36       0.47      0.63      0.54       134\n",
      "         37       0.00      0.00      0.00         7\n",
      "         38       1.00      0.12      0.21        52\n",
      "         39       0.00      0.00      0.00        26\n",
      "         40       0.89      0.40      0.56        42\n",
      "         41       0.91      0.24      0.38        42\n",
      "         42       0.67      0.48      0.56        97\n",
      "         43       0.00      0.00      0.00         3\n",
      "         44       0.92      0.63      0.75        71\n",
      "         45       0.00      0.00      0.00        22\n",
      "         46       0.00      0.00      0.00        14\n",
      "         47       0.64      0.94      0.76       118\n",
      "         48       1.00      0.10      0.18        61\n",
      "         49       0.46      0.88      0.60       125\n",
      "         50       0.80      0.10      0.17        42\n",
      "\n",
      "avg / total       0.61      0.51      0.47      2790\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victorkwak/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Top 1 accuracy:\\n', top_n_accuracy(y_val, nb_probs, 1))\n",
    "print('Top 5 accuracy:\\n', top_n_accuracy(y_val, nb_probs, 5))\n",
    "print(classification_report(y_val, nb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC(penalty='l2', loss='squared_hinge', multi_class='ovr', max_iter=1000)\n",
    "svm.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.651612903226\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         5\n",
      "          1       0.00      0.00      0.00         7\n",
      "          2       0.39      0.47      0.43        55\n",
      "          3       0.85      0.63      0.72        27\n",
      "          4       0.93      0.56      0.70        50\n",
      "          5       0.67      0.71      0.69        98\n",
      "          6       0.91      0.70      0.79        44\n",
      "          7       0.81      0.64      0.72        59\n",
      "          8       0.38      0.42      0.39        36\n",
      "          9       0.68      0.70      0.69       155\n",
      "         10       0.25      0.33      0.29         6\n",
      "         11       0.76      0.82      0.79       122\n",
      "         12       0.21      0.21      0.21        28\n",
      "         13       1.00      0.78      0.88        18\n",
      "         14       0.61      0.71      0.66       145\n",
      "         15       0.70      0.69      0.69        77\n",
      "         16       0.94      0.68      0.79        47\n",
      "         17       0.79      0.95      0.86        20\n",
      "         18       0.86      0.91      0.89        47\n",
      "         19       0.60      0.55      0.57        86\n",
      "         20       0.67      1.00      0.80         2\n",
      "         21       0.85      0.59      0.70        39\n",
      "         22       0.62      0.57      0.59        23\n",
      "         23       0.55      0.57      0.56        87\n",
      "         24       0.50      0.25      0.33         4\n",
      "         25       0.42      0.62      0.50        77\n",
      "         26       0.62      0.69      0.65       124\n",
      "         27       1.00      0.50      0.67         2\n",
      "         28       0.70      0.41      0.52        17\n",
      "         29       0.25      0.18      0.21        17\n",
      "         30       0.57      0.47      0.51        73\n",
      "         31       0.60      0.69      0.65       117\n",
      "         32       0.79      0.75      0.77        20\n",
      "         33       0.68      0.64      0.66       104\n",
      "         34       0.72      0.83      0.77        69\n",
      "         35       0.73      0.41      0.52        27\n",
      "         36       0.58      0.66      0.62       134\n",
      "         37       0.50      0.14      0.22         7\n",
      "         38       0.72      0.54      0.62        52\n",
      "         39       0.54      0.27      0.36        26\n",
      "         40       0.71      0.69      0.70        42\n",
      "         41       0.51      0.62      0.56        42\n",
      "         42       0.64      0.51      0.57        97\n",
      "         43       0.67      0.67      0.67         3\n",
      "         44       0.89      0.76      0.82        71\n",
      "         45       0.50      0.36      0.42        22\n",
      "         46       0.69      0.79      0.73        14\n",
      "         47       0.84      0.89      0.86       118\n",
      "         48       0.54      0.62      0.58        61\n",
      "         49       0.71      0.80      0.75       125\n",
      "         50       0.51      0.48      0.49        42\n",
      "\n",
      "avg / total       0.66      0.65      0.65      2790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_predictions = svm.predict(X_val_vectors)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(accuracy_score(y_val, svm_predictions))\n",
    "print(classification_report(y_val, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "\n",
    "tagged_documents = []\n",
    "tokens = None\n",
    "for text, label in zip(X_train, y_train):\n",
    "    text = text.lower()\n",
    "    tokens = utils.simple_preprocess(text)\n",
    "    tagged_documents.append(TaggedDocument(tokens, [label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['what', 'is', 'going', 'on', 'with', 'spam', 'links', 'on', 'zsh'], tags=[50]),\n",
       " TaggedDocument(words=['how', 'citus', 'works'], tags=[9]),\n",
       " TaggedDocument(words=['framework', 'for', 'building', 'websites', 'express', 'handlebars', 'mysql'], tags=[35]),\n",
       " TaggedDocument(words=['just', 'mempty', 'gt', 'nothing'], tags=[23]),\n",
       " TaggedDocument(words=['paul', 'vixie', 'of', 'dns', 'fame', 'to', 'keynote', 'postgresopen', 'sv'], tags=[9])]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(size=64, window=7, min_count=1, workers=4, iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1316832"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build_vocab(tagged_documents)\n",
    "model.train(tagged_documents, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors = X_train.map(lambda title: model.infer_vector(utils.simple_preprocess(title))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors = np.array(list(X_train_vectors), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8369, 64)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC(penalty='l2', loss='squared_hinge', multi_class='ovr', max_iter=1000)\n",
    "svm.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_vectors = X_val.map(lambda title: model.infer_vector(utils.simple_preprocess(title))).values\n",
    "X_val_vectors = np.array(list(X_val_vectors), dtype=np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are still some rows that contain abnormal vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predictions = svm.predict(X_val_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.519713261649\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         5\n",
      "          1       0.00      0.00      0.00         7\n",
      "          2       0.35      0.33      0.34        55\n",
      "          3       0.00      0.00      0.00        27\n",
      "          4       0.80      0.48      0.60        50\n",
      "          5       0.62      0.61      0.62        98\n",
      "          6       0.50      0.34      0.41        44\n",
      "          7       0.60      0.68      0.63        59\n",
      "          8       0.00      0.00      0.00        36\n",
      "          9       0.49      0.67      0.56       155\n",
      "         10       0.00      0.00      0.00         6\n",
      "         11       0.61      0.69      0.65       122\n",
      "         12       0.00      0.00      0.00        28\n",
      "         13       0.82      0.50      0.62        18\n",
      "         14       0.42      0.57      0.49       145\n",
      "         15       0.57      0.65      0.61        77\n",
      "         16       1.00      0.02      0.04        47\n",
      "         17       0.86      0.95      0.90        20\n",
      "         18       0.83      0.85      0.84        47\n",
      "         19       0.51      0.53      0.52        86\n",
      "         20       0.00      0.00      0.00         2\n",
      "         21       0.86      0.49      0.62        39\n",
      "         22       0.00      0.00      0.00        23\n",
      "         23       0.39      0.36      0.37        87\n",
      "         24       0.00      0.00      0.00         4\n",
      "         25       0.40      0.44      0.42        77\n",
      "         26       0.45      0.67      0.54       124\n",
      "         27       0.00      0.00      0.00         2\n",
      "         28       0.57      0.24      0.33        17\n",
      "         29       0.00      0.00      0.00        17\n",
      "         30       0.43      0.42      0.43        73\n",
      "         31       0.54      0.57      0.56       117\n",
      "         32       1.00      0.15      0.26        20\n",
      "         33       0.55      0.66      0.60       104\n",
      "         34       0.70      0.83      0.76        69\n",
      "         35       0.00      0.00      0.00        27\n",
      "         36       0.46      0.57      0.51       134\n",
      "         37       0.00      0.00      0.00         7\n",
      "         38       0.62      0.58      0.60        52\n",
      "         39       0.00      0.00      0.00        26\n",
      "         40       0.63      0.69      0.66        42\n",
      "         41       0.37      0.31      0.34        42\n",
      "         42       0.44      0.47      0.46        97\n",
      "         43       0.00      0.00      0.00         3\n",
      "         44       0.75      0.70      0.72        71\n",
      "         45       0.00      0.00      0.00        22\n",
      "         46       0.00      0.00      0.00        14\n",
      "         47       0.63      0.84      0.72       118\n",
      "         48       0.34      0.21      0.26        61\n",
      "         49       0.40      0.70      0.51       125\n",
      "         50       0.47      0.33      0.39        42\n",
      "\n",
      "avg / total       0.49      0.52      0.49      2790\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victorkwak/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_val, svm_predictions))\n",
    "print(classification_report(y_val, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH_STOP_WORDS = frozenset([\n",
    "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
    "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
    "    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
    "    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
    "    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
    "    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
    "    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
    "    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\",\n",
    "    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
    "    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
    "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
    "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
    "    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
    "    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
    "    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
    "    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
    "    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
    "    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
    "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
    "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
    "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
    "    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
    "    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
    "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
    "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
    "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
    "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "\"yourselves\"])\n",
    "\n",
    "\n",
    "def format_for_fastext(X, y, filename):\n",
    "    prefix = '__label__'\n",
    "    f = open(''.join(['data/', filename]), 'w')\n",
    "    for title, label in zip(X, y):\n",
    "        title = title.lower()\n",
    "        tokens = utils.simple_preprocess(title)\n",
    "        tokens = [token for token in tokens if token not in ENGLISH_STOP_WORDS]\n",
    "        f.write(''.join([prefix, str(label), ' ', ' '.join(tokens), '\\n']))\n",
    "    f.close()\n",
    "    \n",
    "format_for_fastext(X_train, y_train, 'reddit_fasttext_train.txt')\n",
    "format_for_fastext(X_val, y_val, 'reddit_fasttext_val.txt')\n",
    "format_for_fastext(X_test, y_test, 'reddit_fasttext_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6232974910394266\n",
      "0.6232974910394266\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "classifier = fasttext.supervised('data/reddit_fasttext_train.txt', 'model', \n",
    "                                 label_prefix='__label__', \n",
    "                                 lr=0.1,\n",
    "                                 epoch=24,\n",
    "                                 dim=64,\n",
    "                                 minn=2\n",
    "                                )\n",
    "results = classifier.test('data/reddit_fasttext_val.txt')\n",
    "print(results.precision)\n",
    "print(results.recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6229390681003584\n",
      "0.6229390681003584\n"
     ]
    }
   ],
   "source": [
    "results = classifier.test('data/reddit_fasttext_test.txt')\n",
    "print(results.precision)\n",
    "print(results.recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fasttext_predictions(X, model):\n",
    "    predictions = []\n",
    "    for text in X:\n",
    "        predictions.append(int(model.predict(text)[0][0][0]))\n",
    "    return np.array(predictions)\n",
    "\n",
    "fasttext_predictions = fasttext_predictions(X_val, classifier)\n",
    "fasttext_predictions[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012903225806451613"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, fasttext_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
