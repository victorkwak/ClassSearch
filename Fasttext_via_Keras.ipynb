{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data/cs_subs.csv')  # unzip this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['subreddit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624289, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624281, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Android                61202\n",
       "learnprogramming       35288\n",
       "cscareerquestions      32935\n",
       "Windows10              27726\n",
       "webdev                 26849\n",
       "dataisbeautiful        24388\n",
       "softwaregore           23741\n",
       "web_design             22159\n",
       "ProgrammerHumor        19206\n",
       "learnpython            17634\n",
       "raspberry_pi           15659\n",
       "iOSBeta                14508\n",
       "linux                  14058\n",
       "javascript             12971\n",
       "linuxquestions         11464\n",
       "hackernews             11134\n",
       "Python                 11119\n",
       "windows                10132\n",
       "androiddev             10130\n",
       "mac                     9841\n",
       "ios                     9754\n",
       "arduino                 9603\n",
       "java                    9401\n",
       "networking              9378\n",
       "linux4noobs             8004\n",
       "androidthemes           7895\n",
       "chrome                  5862\n",
       "iOSProgramming          5647\n",
       "rust                    5489\n",
       "datascience             5374\n",
       "                       ...  \n",
       "redis                    241\n",
       "dartlang                 240\n",
       "programmerreactions      237\n",
       "Julia                    217\n",
       "reviewmycode             216\n",
       "zsh                      210\n",
       "OSXTweaks                198\n",
       "erlang                   186\n",
       "MaterialDesign           179\n",
       "d3js                     179\n",
       "npm                      164\n",
       "c_language               143\n",
       "learnphp                 120\n",
       "Heroku                   118\n",
       "dailyprogrammer          114\n",
       "cakephp                  113\n",
       "learnruby                106\n",
       "mariadb                   95\n",
       "tinycode                  93\n",
       "groovy                    90\n",
       "pythoncoding              88\n",
       "vagrant                   77\n",
       "Cprog                     38\n",
       "androiddesign             36\n",
       "osxterminal               31\n",
       "learnlaravel              28\n",
       "haskelltil                24\n",
       "shell                     24\n",
       "AskCompSci                17\n",
       "dotfiles                  17\n",
       "Name: subreddit, Length: 136, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>277178</th>\n",
       "      <td>Copy selected text to clipboard and paste it i...</td>\n",
       "      <td>2</td>\n",
       "      <td>learnpython</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358274</th>\n",
       "      <td>My Best JavaScript Learning Resources</td>\n",
       "      <td>1</td>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246508</th>\n",
       "      <td>Why am I printing an extra newline?</td>\n",
       "      <td>2</td>\n",
       "      <td>learnpython</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84413</th>\n",
       "      <td>IT Managed Services Georgia</td>\n",
       "      <td>1</td>\n",
       "      <td>softwaredevelopment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472977</th>\n",
       "      <td>Google Maps High Memory Usage</td>\n",
       "      <td>1</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325749</th>\n",
       "      <td>Is there a Chrome extension that can clean up ...</td>\n",
       "      <td>2</td>\n",
       "      <td>chrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108572</th>\n",
       "      <td>I know the basics of Javascript, HTML, CSS. I'...</td>\n",
       "      <td>2</td>\n",
       "      <td>learnprogramming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48704</th>\n",
       "      <td>E-commerce website development</td>\n",
       "      <td>1</td>\n",
       "      <td>webdev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585244</th>\n",
       "      <td>Samsung 8, LG 6 or Pixel?</td>\n",
       "      <td>1</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117937</th>\n",
       "      <td>Hypermac concert cable to USB c</td>\n",
       "      <td>1</td>\n",
       "      <td>mac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  score  \\\n",
       "277178  Copy selected text to clipboard and paste it i...      2   \n",
       "358274              My Best JavaScript Learning Resources      1   \n",
       "246508                Why am I printing an extra newline?      2   \n",
       "84413                         IT Managed Services Georgia      1   \n",
       "472977                      Google Maps High Memory Usage      1   \n",
       "325749  Is there a Chrome extension that can clean up ...      2   \n",
       "108572  I know the basics of Javascript, HTML, CSS. I'...      2   \n",
       "48704                      E-commerce website development      1   \n",
       "585244                          Samsung 8, LG 6 or Pixel?      1   \n",
       "117937                    Hypermac concert cable to USB c      1   \n",
       "\n",
       "                  subreddit  \n",
       "277178          learnpython  \n",
       "358274           javascript  \n",
       "246508          learnpython  \n",
       "84413   softwaredevelopment  \n",
       "472977              Android  \n",
       "325749               chrome  \n",
       "108572     learnprogramming  \n",
       "48704                webdev  \n",
       "585244              Android  \n",
       "117937                  mac  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are filtering non-latin words, and also subreddits that have less than 150 posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data['subreddit'].value_counts()\n",
    "counts = counts[counts > 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_values = list(counts.index)\n",
    "data = data[data['subreddit'].isin(top_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Android                61202\n",
       "learnprogramming       35288\n",
       "cscareerquestions      32935\n",
       "Windows10              27726\n",
       "webdev                 26849\n",
       "dataisbeautiful        24388\n",
       "softwaregore           23741\n",
       "web_design             22159\n",
       "ProgrammerHumor        19206\n",
       "learnpython            17634\n",
       "raspberry_pi           15659\n",
       "iOSBeta                14508\n",
       "linux                  14058\n",
       "javascript             12971\n",
       "linuxquestions         11464\n",
       "hackernews             11134\n",
       "Python                 11119\n",
       "windows                10132\n",
       "androiddev             10130\n",
       "mac                     9841\n",
       "ios                     9754\n",
       "arduino                 9603\n",
       "java                    9401\n",
       "networking              9378\n",
       "linux4noobs             8004\n",
       "androidthemes           7895\n",
       "chrome                  5862\n",
       "iOSProgramming          5647\n",
       "rust                    5489\n",
       "datascience             5374\n",
       "                       ...  \n",
       "windowsinsiders          683\n",
       "jquery                   667\n",
       "operabrowser             647\n",
       "browsers                 586\n",
       "watchOSBeta              581\n",
       "LanguageTechnology       528\n",
       "macapps                  526\n",
       "mongodb                  507\n",
       "rubyonrails              455\n",
       "itsaunixsystem           449\n",
       "djangolearning           428\n",
       "nginx                    420\n",
       "haskellquestions         394\n",
       "lua                      363\n",
       "symfony                  357\n",
       "windows8                 334\n",
       "cprogramming             328\n",
       "Meteor                   316\n",
       "DatabaseHelp             312\n",
       "redis                    241\n",
       "dartlang                 240\n",
       "programmerreactions      237\n",
       "Julia                    217\n",
       "reviewmycode             216\n",
       "zsh                      210\n",
       "OSXTweaks                198\n",
       "erlang                   186\n",
       "d3js                     179\n",
       "MaterialDesign           179\n",
       "npm                      164\n",
       "Name: subreddit, Length: 117, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622909, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of data. Especially for my Macbook. Let's see the average reddit score (upvotes + downvotes) for each subreddit to filter out. I want to do mean and not median since median would just arbitrarily cut the data in half. Hopefully filtering by mean will take relatively larger chunks out of the more popular subreddits than the less popular ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = {}\n",
    "for subreddit in data['subreddit'].unique():\n",
    "    means[subreddit] = data[data['subreddit'] == subreddit]['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "filtered = []\n",
    "\n",
    "for subreddit in data['subreddit'].unique():\n",
    "    filtered.append(data.loc[(data['subreddit'] == subreddit) & (data['score'] >= means[subreddit])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = pd.concat(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Android                6807\n",
       "linuxquestions         3893\n",
       "cscareerquestions      3772\n",
       "learnpython            3081\n",
       "webdev                 2565\n",
       "hackernews             2563\n",
       "iOSBeta                2424\n",
       "Windows10              2338\n",
       "linux4noobs            2275\n",
       "ProgrammerHumor        2194\n",
       "networking             2174\n",
       "androiddev             2026\n",
       "linux                  2013\n",
       "windows                2005\n",
       "javascript             1880\n",
       "learnprogramming       1813\n",
       "softwaregore           1746\n",
       "ios                    1737\n",
       "java                   1672\n",
       "androidthemes          1664\n",
       "chrome                 1548\n",
       "Python                 1474\n",
       "aws                    1471\n",
       "rust                   1466\n",
       "web_design             1361\n",
       "javahelp               1326\n",
       "arduino                1205\n",
       "iOSProgramming         1190\n",
       "mac                    1150\n",
       "csshelp                1101\n",
       "                       ... \n",
       "operabrowser            221\n",
       "mongodb                 197\n",
       "macapps                 189\n",
       "windowsinsiders         189\n",
       "LanguageTechnology      181\n",
       "softwaredevelopment     178\n",
       "djangolearning          173\n",
       "watchOSBeta             149\n",
       "browsers                142\n",
       "itsaunixsystem          138\n",
       "symfony                 124\n",
       "lua                     121\n",
       "nginx                   120\n",
       "windows8                119\n",
       "rubyonrails             117\n",
       "haskellquestions        117\n",
       "programmerreactions     117\n",
       "dartlang                103\n",
       "Meteor                  101\n",
       "redis                    86\n",
       "Julia                    82\n",
       "npm                      74\n",
       "erlang                   72\n",
       "zsh                      69\n",
       "OSXTweaks                67\n",
       "DatabaseHelp             59\n",
       "MaterialDesign           51\n",
       "d3js                     49\n",
       "cprogramming             48\n",
       "reviewmycode             44\n",
       "Name: subreddit, Length: 117, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99057, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98941, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = filtered_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40902</th>\n",
       "      <td>App Transport Security app approval exemption</td>\n",
       "      <td>11</td>\n",
       "      <td>iOSProgramming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590511</th>\n",
       "      <td>Bad Parameter Sniffing Decision Flow Chart</td>\n",
       "      <td>6</td>\n",
       "      <td>SQLServer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95569</th>\n",
       "      <td>Tesla Passes Ford by Market Value</td>\n",
       "      <td>7</td>\n",
       "      <td>hackernews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443359</th>\n",
       "      <td>GNU Personal Expense Manager</td>\n",
       "      <td>13</td>\n",
       "      <td>linux4noobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122426</th>\n",
       "      <td>PHP Traits…a wonderful home for shared Laravel...</td>\n",
       "      <td>22</td>\n",
       "      <td>laravel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461628</th>\n",
       "      <td>Node v8.5.0 (Current)</td>\n",
       "      <td>42</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613160</th>\n",
       "      <td>Collectively – an open platform to enhance com...</td>\n",
       "      <td>30</td>\n",
       "      <td>opensource</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523967</th>\n",
       "      <td>Gigabit Router/Firewall for Small Business</td>\n",
       "      <td>10</td>\n",
       "      <td>networking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523467</th>\n",
       "      <td>HTTPS: Private Keys on Web Servers</td>\n",
       "      <td>18</td>\n",
       "      <td>crypto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149315</th>\n",
       "      <td>Painting my room with WebVR</td>\n",
       "      <td>49</td>\n",
       "      <td>webdev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329628</th>\n",
       "      <td>[DEV] \"Now Playing\" History - I've developed a...</td>\n",
       "      <td>236</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585051</th>\n",
       "      <td>A chat bubble appeared on the lock screen. Do ...</td>\n",
       "      <td>49</td>\n",
       "      <td>Windows10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588702</th>\n",
       "      <td>[Feature] Happened while updating to beta 6</td>\n",
       "      <td>76</td>\n",
       "      <td>iOSBeta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536926</th>\n",
       "      <td>Building a Windows 10 IoT C# traffic monitor</td>\n",
       "      <td>24</td>\n",
       "      <td>csharp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159021</th>\n",
       "      <td>tl; dr Memory Precedence</td>\n",
       "      <td>8</td>\n",
       "      <td>learnpython</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570625</th>\n",
       "      <td>capacity not available vs. capacity oversubscr...</td>\n",
       "      <td>8</td>\n",
       "      <td>aws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270483</th>\n",
       "      <td>Nuitka Release 0.5.28</td>\n",
       "      <td>45</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70745</th>\n",
       "      <td>Rust: confident, productive systems programmin...</td>\n",
       "      <td>56</td>\n",
       "      <td>rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26506</th>\n",
       "      <td>Virtual machines and GPU pass-through questions?</td>\n",
       "      <td>5</td>\n",
       "      <td>linuxquestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91508</th>\n",
       "      <td>Inconsistency in the Start menu tiles</td>\n",
       "      <td>16</td>\n",
       "      <td>Windows10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  score  \\\n",
       "40902       App Transport Security app approval exemption     11   \n",
       "590511         Bad Parameter Sniffing Decision Flow Chart      6   \n",
       "95569                   Tesla Passes Ford by Market Value      7   \n",
       "443359                       GNU Personal Expense Manager     13   \n",
       "122426  PHP Traits…a wonderful home for shared Laravel...     22   \n",
       "461628                              Node v8.5.0 (Current)     42   \n",
       "613160  Collectively – an open platform to enhance com...     30   \n",
       "523967         Gigabit Router/Firewall for Small Business     10   \n",
       "523467                 HTTPS: Private Keys on Web Servers     18   \n",
       "149315                        Painting my room with WebVR     49   \n",
       "329628  [DEV] \"Now Playing\" History - I've developed a...    236   \n",
       "585051  A chat bubble appeared on the lock screen. Do ...     49   \n",
       "588702        [Feature] Happened while updating to beta 6     76   \n",
       "536926       Building a Windows 10 IoT C# traffic monitor     24   \n",
       "159021                           tl; dr Memory Precedence      8   \n",
       "570625  capacity not available vs. capacity oversubscr...      8   \n",
       "270483                              Nuitka Release 0.5.28     45   \n",
       "70745   Rust: confident, productive systems programmin...     56   \n",
       "26506    Virtual machines and GPU pass-through questions?      5   \n",
       "91508               Inconsistency in the Start menu tiles     16   \n",
       "\n",
       "             subreddit  \n",
       "40902   iOSProgramming  \n",
       "590511       SQLServer  \n",
       "95569       hackernews  \n",
       "443359     linux4noobs  \n",
       "122426         laravel  \n",
       "461628            node  \n",
       "613160      opensource  \n",
       "523967      networking  \n",
       "523467          crypto  \n",
       "149315          webdev  \n",
       "329628         Android  \n",
       "585051       Windows10  \n",
       "588702         iOSBeta  \n",
       "536926          csharp  \n",
       "159021     learnpython  \n",
       "570625             aws  \n",
       "270483          Python  \n",
       "70745             rust  \n",
       "26506   linuxquestions  \n",
       "91508        Windows10  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_data['title']\n",
    "y = filtered_data['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data into train (60%), val (20%), and test (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "def create_ngram_set(input_list, ngram_value=2):\n",
    "    \"\"\"\n",
    "    Extract a set of n-grams from a list of integers.\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=2)\n",
    "    {(4, 9), (4, 1), (1, 4), (9, 4)}\n",
    "    >>> create_ngram_set([1, 4, 9, 4, 1, 4], ngram_value=3)\n",
    "    [(1, 4, 9), (4, 9, 4), (9, 4, 1), (4, 1, 4)]\n",
    "    \"\"\"\n",
    "    return set(zip(*[input_list[i:] for i in range(ngram_value)]))\n",
    "\n",
    "def add_ngram(sequences, token_indice, ngram_range=2):\n",
    "    \"\"\"\n",
    "    Augment the input list of list (sequences) by appending n-grams values.\n",
    "    Example: adding bi-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=2)\n",
    "    [[1, 3, 4, 5, 1337, 2017], [1, 3, 7, 9, 2, 1337, 42]]\n",
    "    Example: adding tri-gram\n",
    "    >>> sequences = [[1, 3, 4, 5], [1, 3, 7, 9, 2]]\n",
    "    >>> token_indice = {(1, 3): 1337, (9, 2): 42, (4, 5): 2017, (7, 9, 2): 2018}\n",
    "    >>> add_ngram(sequences, token_indice, ngram_range=3)\n",
    "    [[1, 3, 4, 5, 1337], [1, 3, 7, 9, 2, 1337, 2018]]\n",
    "    \"\"\"\n",
    "    new_sequences = []\n",
    "    for input_list in sequences:\n",
    "        new_list = input_list[:]\n",
    "        for i in range(len(new_list) - ngram_range + 1):\n",
    "            for ngram_value in range(2, ngram_range + 1):\n",
    "                ngram = tuple(new_list[i:i + ngram_value])\n",
    "                if ngram in token_indice:\n",
    "                    new_list.append(token_indice[ngram])\n",
    "        new_sequences.append(new_list)\n",
    "\n",
    "    return new_sequences\n",
    "\n",
    "def preprocess(X_train, y_train, X_val, y_val, X_test, y_test, ngram_range=2, max_features=1000, max_len=30):\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(pd.concat([X_train, X_val, X_test]))\n",
    "    \n",
    "    X_train = tokenizer.texts_to_sequences(X_train)\n",
    "    X_val = tokenizer.texts_to_sequences(X_val)\n",
    "    X_test = tokenizer.texts_to_sequences(X_test)\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_val = label_encoder.transform(y_val)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "    \n",
    "    label_binarizer = LabelBinarizer()\n",
    "    y_train = label_binarizer.fit_transform(y_train)\n",
    "    y_val = label_binarizer.transform(y_val)\n",
    "    y_test = label_binarizer.transform(y_test)\n",
    "    \n",
    "    token_indice = None\n",
    "    \n",
    "    if ngram_range > 1:\n",
    "        ngram_set = set()\n",
    "        for input_list in X_train:\n",
    "            for i in range(2, ngram_range + 1):\n",
    "                set_of_ngram = create_ngram_set(input_list, ngram_value=i)\n",
    "                ngram_set.update(set_of_ngram)\n",
    "                \n",
    "        start_index = max_features + 1\n",
    "        token_indice = {v: k + start_index for k, v in enumerate(ngram_set)}\n",
    "        indice_token = {token_indice[k]: k for k in token_indice}\n",
    "                \n",
    "        max_features = np.max(list(indice_token.keys())) + 1\n",
    "        \n",
    "        X_train = add_ngram(X_train, token_indice, ngram_range)\n",
    "        X_val = add_ngram(X_val, token_indice, ngram_range)\n",
    "        X_test = add_ngram(X_test, token_indice, ngram_range)\n",
    "        \n",
    "    X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "    X_val = sequence.pad_sequences(X_val, maxlen=max_len)\n",
    "    X_test = sequence.pad_sequences(X_test, maxlen=max_len)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_val, tokenizer, label_binarizer, label_encoder, token_indice, max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59364,)\n",
      "(19788,)\n",
      "(19789,)\n",
      "(59364,)\n",
      "(19788,)\n",
      "(19789,)\n",
      "max_features: 500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=17)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=31)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_val, tokenizer, label_binarizer, label_encoder, token_indice, max_features = preprocess(\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, ngram_range=1, max_features=500, max_len=20)\n",
    "\n",
    "print('max_features:', max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59364 samples, validate on 19789 samples\n",
      "Epoch 1/1000\n",
      "59364/59364 [==============================] - 4s 69us/step - loss: 4.3134 - acc: 0.0659 - val_loss: 4.2050 - val_acc: 0.0688\n",
      "Epoch 2/1000\n",
      "59364/59364 [==============================] - 3s 52us/step - loss: 4.1248 - acc: 0.0725 - val_loss: 4.0330 - val_acc: 0.0877\n",
      "Epoch 3/1000\n",
      "59364/59364 [==============================] - 3s 52us/step - loss: 3.9056 - acc: 0.1355 - val_loss: 3.7768 - val_acc: 0.1848\n",
      "Epoch 4/1000\n",
      "59364/59364 [==============================] - 3s 53us/step - loss: 3.6361 - acc: 0.2179 - val_loss: 3.5129 - val_acc: 0.2485\n",
      "Epoch 5/1000\n",
      "59364/59364 [==============================] - 3s 53us/step - loss: 3.3890 - acc: 0.2695 - val_loss: 3.2975 - val_acc: 0.2894\n",
      "Epoch 6/1000\n",
      "59364/59364 [==============================] - 3s 54us/step - loss: 3.1982 - acc: 0.3037 - val_loss: 3.1434 - val_acc: 0.3143\n",
      "Epoch 7/1000\n",
      "59364/59364 [==============================] - 3s 53us/step - loss: 3.0619 - acc: 0.3271 - val_loss: 3.0353 - val_acc: 0.3328\n",
      "Epoch 8/1000\n",
      "59364/59364 [==============================] - 3s 53us/step - loss: 2.9652 - acc: 0.3393 - val_loss: 2.9614 - val_acc: 0.3364\n",
      "Epoch 9/1000\n",
      "59364/59364 [==============================] - 3s 53us/step - loss: 2.8957 - acc: 0.3489 - val_loss: 2.9094 - val_acc: 0.3459\n",
      "Epoch 10/1000\n",
      "59364/59364 [==============================] - 3s 53us/step - loss: 2.8442 - acc: 0.3553 - val_loss: 2.8693 - val_acc: 0.3520\n",
      "Epoch 11/1000\n",
      "59364/59364 [==============================] - 3s 53us/step - loss: 2.8044 - acc: 0.3612 - val_loss: 2.8401 - val_acc: 0.3566\n",
      "Epoch 12/1000\n",
      "59364/59364 [==============================] - 3s 53us/step - loss: 2.7724 - acc: 0.3663 - val_loss: 2.8183 - val_acc: 0.3585\n",
      "Epoch 13/1000\n",
      "59364/59364 [==============================] - 3s 55us/step - loss: 2.7460 - acc: 0.3691 - val_loss: 2.7980 - val_acc: 0.3600\n",
      "Epoch 14/1000\n",
      "59364/59364 [==============================] - 3s 55us/step - loss: 2.7233 - acc: 0.3716 - val_loss: 2.7827 - val_acc: 0.3635\n",
      "Epoch 15/1000\n",
      "59364/59364 [==============================] - 3s 54us/step - loss: 2.7039 - acc: 0.3753 - val_loss: 2.7698 - val_acc: 0.3646\n",
      "Epoch 16/1000\n",
      "59364/59364 [==============================] - 3s 54us/step - loss: 2.6865 - acc: 0.3776 - val_loss: 2.7586 - val_acc: 0.3660\n",
      "Epoch 17/1000\n",
      "59364/59364 [==============================] - 3s 55us/step - loss: 2.6714 - acc: 0.3798 - val_loss: 2.7487 - val_acc: 0.3646\n",
      "Epoch 18/1000\n",
      "59364/59364 [==============================] - 3s 55us/step - loss: 2.6576 - acc: 0.3811 - val_loss: 2.7416 - val_acc: 0.3674\n",
      "Epoch 19/1000\n",
      "59364/59364 [==============================] - 3s 55us/step - loss: 2.6454 - acc: 0.3834 - val_loss: 2.7333 - val_acc: 0.3699\n",
      "Epoch 20/1000\n",
      "59364/59364 [==============================] - 3s 55us/step - loss: 2.6341 - acc: 0.3857 - val_loss: 2.7278 - val_acc: 0.3712\n",
      "Epoch 21/1000\n",
      "59364/59364 [==============================] - 3s 55us/step - loss: 2.6237 - acc: 0.3862 - val_loss: 2.7220 - val_acc: 0.3709\n",
      "Epoch 22/1000\n",
      "59364/59364 [==============================] - 3s 55us/step - loss: 2.6141 - acc: 0.3889 - val_loss: 2.7193 - val_acc: 0.3719\n",
      "Epoch 23/1000\n",
      "59364/59364 [==============================] - 3s 56us/step - loss: 2.6055 - acc: 0.3906 - val_loss: 2.7140 - val_acc: 0.3736\n",
      "Epoch 24/1000\n",
      "59364/59364 [==============================] - 3s 56us/step - loss: 2.5976 - acc: 0.3910 - val_loss: 2.7112 - val_acc: 0.3730\n",
      "Epoch 25/1000\n",
      "59364/59364 [==============================] - 3s 56us/step - loss: 2.5900 - acc: 0.3922 - val_loss: 2.7079 - val_acc: 0.3725\n",
      "Epoch 26/1000\n",
      "59364/59364 [==============================] - 3s 56us/step - loss: 2.5829 - acc: 0.3937 - val_loss: 2.7055 - val_acc: 0.3747\n",
      "Epoch 27/1000\n",
      "59364/59364 [==============================] - 3s 56us/step - loss: 2.5762 - acc: 0.3947 - val_loss: 2.7036 - val_acc: 0.3746\n",
      "Epoch 28/1000\n",
      "59364/59364 [==============================] - 3s 56us/step - loss: 2.5701 - acc: 0.3957 - val_loss: 2.7004 - val_acc: 0.3748\n",
      "Epoch 29/1000\n",
      "59364/59364 [==============================] - 3s 56us/step - loss: 2.5642 - acc: 0.3958 - val_loss: 2.7000 - val_acc: 0.3762\n",
      "Epoch 30/1000\n",
      "59364/59364 [==============================] - 3s 57us/step - loss: 2.5588 - acc: 0.3964 - val_loss: 2.6980 - val_acc: 0.3759\n",
      "Epoch 31/1000\n",
      "59364/59364 [==============================] - 3s 57us/step - loss: 2.5536 - acc: 0.3975 - val_loss: 2.6964 - val_acc: 0.3753\n",
      "Epoch 32/1000\n",
      "59364/59364 [==============================] - 3s 58us/step - loss: 2.5487 - acc: 0.3979 - val_loss: 2.6953 - val_acc: 0.3764\n",
      "Epoch 33/1000\n",
      "59364/59364 [==============================] - 3s 58us/step - loss: 2.5436 - acc: 0.3985 - val_loss: 2.6946 - val_acc: 0.3775\n",
      "Epoch 34/1000\n",
      "59364/59364 [==============================] - 3s 58us/step - loss: 2.5393 - acc: 0.3999 - val_loss: 2.6935 - val_acc: 0.3778\n",
      "Epoch 35/1000\n",
      "59364/59364 [==============================] - 3s 59us/step - loss: 2.5349 - acc: 0.4001 - val_loss: 2.6936 - val_acc: 0.3771\n",
      "Epoch 36/1000\n",
      "59364/59364 [==============================] - 3s 58us/step - loss: 2.5308 - acc: 0.4001 - val_loss: 2.6927 - val_acc: 0.3777\n",
      "Epoch 37/1000\n",
      "59364/59364 [==============================] - 4s 60us/step - loss: 2.5270 - acc: 0.4007 - val_loss: 2.6915 - val_acc: 0.3779\n",
      "Epoch 38/1000\n",
      "59364/59364 [==============================] - 4s 59us/step - loss: 2.5231 - acc: 0.4006 - val_loss: 2.6930 - val_acc: 0.3774\n",
      "Epoch 39/1000\n",
      "59364/59364 [==============================] - 4s 59us/step - loss: 2.5195 - acc: 0.4011 - val_loss: 2.6920 - val_acc: 0.3779\n",
      "Epoch 40/1000\n",
      "59364/59364 [==============================] - 4s 59us/step - loss: 2.5160 - acc: 0.4025 - val_loss: 2.6911 - val_acc: 0.3784\n",
      "Epoch 41/1000\n",
      "59364/59364 [==============================] - 4s 60us/step - loss: 2.5127 - acc: 0.4025 - val_loss: 2.6920 - val_acc: 0.3774\n",
      "Epoch 42/1000\n",
      "59364/59364 [==============================] - 4s 66us/step - loss: 2.5095 - acc: 0.4028 - val_loss: 2.6899 - val_acc: 0.3775\n",
      "Epoch 43/1000\n",
      "59364/59364 [==============================] - 4s 61us/step - loss: 2.5065 - acc: 0.4032 - val_loss: 2.6913 - val_acc: 0.3775\n",
      "Epoch 44/1000\n",
      "59364/59364 [==============================] - 4s 62us/step - loss: 2.5035 - acc: 0.4036 - val_loss: 2.6904 - val_acc: 0.3773\n",
      "Epoch 45/1000\n",
      "59364/59364 [==============================] - 4s 62us/step - loss: 2.5005 - acc: 0.4041 - val_loss: 2.6903 - val_acc: 0.3791\n",
      "Epoch 46/1000\n",
      "59364/59364 [==============================] - 4s 62us/step - loss: 2.4977 - acc: 0.4044 - val_loss: 2.6909 - val_acc: 0.3732\n",
      "Epoch 47/1000\n",
      "59364/59364 [==============================] - 4s 64us/step - loss: 2.4951 - acc: 0.4046 - val_loss: 2.6924 - val_acc: 0.3770\n",
      "Epoch 48/1000\n",
      "59364/59364 [==============================] - 4s 64us/step - loss: 2.4925 - acc: 0.4052 - val_loss: 2.6902 - val_acc: 0.3777\n",
      "Epoch 49/1000\n",
      "59364/59364 [==============================] - 4s 66us/step - loss: 2.4900 - acc: 0.4055 - val_loss: 2.6916 - val_acc: 0.3782\n",
      "Epoch 50/1000\n",
      "59364/59364 [==============================] - 4s 63us/step - loss: 2.4878 - acc: 0.4055 - val_loss: 2.6909 - val_acc: 0.3783\n",
      "Epoch 51/1000\n",
      "59364/59364 [==============================] - 4s 69us/step - loss: 2.4854 - acc: 0.4063 - val_loss: 2.6912 - val_acc: 0.3776\n",
      "Epoch 52/1000\n",
      "59364/59364 [==============================] - 4s 62us/step - loss: 2.4829 - acc: 0.4061 - val_loss: 2.6925 - val_acc: 0.3771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3575cf98>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras import callbacks\n",
    "import keras.backend as K\n",
    "\n",
    "batch_size = 64\n",
    "embedding_dims = 30\n",
    "epochs = 1000\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, embedding_dims, input_length=X_train.shape[1]))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                         min_delta=0.001,\n",
    "                                         patience=10,\n",
    "                                         mode='min')\n",
    "\n",
    "get_best = callbacks.ModelCheckpoint(monitor='val_loss',\n",
    "                                     filepath='models/keras_fasttext.hdf5',\n",
    "                                     save_best_only=True)\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                        factor=0.0001,\n",
    "                                        min_lr=0.001)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[early_stopping, get_best, reduce_lr],\n",
    "          validation_data=[X_val, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
